// Code generated by mkpreempt.go; DO NOT EDIT.

#include "go_asm.h"
#include "go_tls.h"
#include "asm_amd64.h"
#include "textflag.h"

TEXT ·asyncPreempt(SB),NOSPLIT|NOFRAME,$0-0
	PUSHQ BP
	MOVQ SP, BP
	// Save flags before clobbering them
	PUSHFQ
	// obj doesn't understand ADD/SUB on SP, but does understand ADJSP
	ADJSP $112
	// But vet doesn't know ADJSP, so suppress vet stack checking
	NOP SP
	// Save GPs
	MOVQ AX, 0(SP)
	MOVQ CX, 8(SP)
	MOVQ DX, 16(SP)
	MOVQ BX, 24(SP)
	MOVQ SI, 32(SP)
	MOVQ DI, 40(SP)
	MOVQ R8, 48(SP)
	MOVQ R9, 56(SP)
	MOVQ R10, 64(SP)
	MOVQ R11, 72(SP)
	MOVQ R12, 80(SP)
	MOVQ R13, 88(SP)
	MOVQ R14, 96(SP)
	MOVQ R15, 104(SP)
	// Save extended register state to p.xRegs.scratch
	// Don't make assumptions about ABI register state. See mkpreempt.go
	get_tls(CX)
	MOVQ g(CX), R14
	MOVQ g_m(R14), AX
	MOVQ m_p(AX), AX
	LEAQ (p_xRegs+xRegPerP_scratch)(AX), AX
	MOVUPS X0, 0(AX)
	MOVUPS X1, 16(AX)
	MOVUPS X2, 32(AX)
	MOVUPS X3, 48(AX)
	MOVUPS X4, 64(AX)
	MOVUPS X5, 80(AX)
	MOVUPS X6, 96(AX)
	MOVUPS X7, 112(AX)
	MOVUPS X8, 128(AX)
	MOVUPS X9, 144(AX)
	MOVUPS X10, 160(AX)
	MOVUPS X11, 176(AX)
	MOVUPS X12, 192(AX)
	MOVUPS X13, 208(AX)
	MOVUPS X14, 224(AX)
	MOVUPS X15, 240(AX)
	CALL ·asyncPreempt2(SB)
	// Restore non-GPs from *p.xRegs.cache
	MOVQ g_m(R14), AX
	MOVQ m_p(AX), AX
	MOVQ (p_xRegs+xRegPerP_cache)(AX), AX
	MOVUPS 240(AX), X15
	MOVUPS 224(AX), X14
	MOVUPS 208(AX), X13
	MOVUPS 192(AX), X12
	MOVUPS 176(AX), X11
	MOVUPS 160(AX), X10
	MOVUPS 144(AX), X9
	MOVUPS 128(AX), X8
	MOVUPS 112(AX), X7
	MOVUPS 96(AX), X6
	MOVUPS 80(AX), X5
	MOVUPS 64(AX), X4
	MOVUPS 48(AX), X3
	MOVUPS 32(AX), X2
	MOVUPS 16(AX), X1
	MOVUPS 0(AX), X0
	// Restore GPs
	MOVQ 104(SP), R15
	MOVQ 96(SP), R14
	MOVQ 88(SP), R13
	MOVQ 80(SP), R12
	MOVQ 72(SP), R11
	MOVQ 64(SP), R10
	MOVQ 56(SP), R9
	MOVQ 48(SP), R8
	MOVQ 40(SP), DI
	MOVQ 32(SP), SI
	MOVQ 24(SP), BX
	MOVQ 16(SP), DX
	MOVQ 8(SP), CX
	MOVQ 0(SP), AX
	ADJSP $-112
	POPFQ
	POPQ BP
	RET
