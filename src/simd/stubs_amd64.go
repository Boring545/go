// Code generated by x/arch/internal/simdgen using 'go run . -xedPath $XED_PATH -o godefs -goroot $GOROOT go.yaml types.yaml categories.yaml'; DO NOT EDIT.

//go:build goexperiment.simd

package simd

/* Absolute */

// Absolute computes the absolute value of each element.
//
// Asm: VPABSB, CPU Feature: AVX
func (x Int8x16) Absolute() Int8x16

// Absolute computes the absolute value of each element.
//
// Asm: VPABSB, CPU Feature: AVX2
func (x Int8x32) Absolute() Int8x32

// Absolute computes the absolute value of each element.
//
// Asm: VPABSB, CPU Feature: AVX512EVEX
func (x Int8x64) Absolute() Int8x64

// Absolute computes the absolute value of each element.
//
// Asm: VPABSW, CPU Feature: AVX
func (x Int16x8) Absolute() Int16x8

// Absolute computes the absolute value of each element.
//
// Asm: VPABSW, CPU Feature: AVX2
func (x Int16x16) Absolute() Int16x16

// Absolute computes the absolute value of each element.
//
// Asm: VPABSW, CPU Feature: AVX512EVEX
func (x Int16x32) Absolute() Int16x32

// Absolute computes the absolute value of each element.
//
// Asm: VPABSD, CPU Feature: AVX
func (x Int32x4) Absolute() Int32x4

// Absolute computes the absolute value of each element.
//
// Asm: VPABSD, CPU Feature: AVX2
func (x Int32x8) Absolute() Int32x8

// Absolute computes the absolute value of each element.
//
// Asm: VPABSD, CPU Feature: AVX512EVEX
func (x Int32x16) Absolute() Int32x16

// Absolute computes the absolute value of each element.
//
// Asm: VPABSQ, CPU Feature: AVX512EVEX
func (x Int64x2) Absolute() Int64x2

// Absolute computes the absolute value of each element.
//
// Asm: VPABSQ, CPU Feature: AVX512EVEX
func (x Int64x4) Absolute() Int64x4

// Absolute computes the absolute value of each element.
//
// Asm: VPABSQ, CPU Feature: AVX512EVEX
func (x Int64x8) Absolute() Int64x8

/* Add */

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPS, CPU Feature: AVX
func (x Float32x4) Add(y Float32x4) Float32x4

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPS, CPU Feature: AVX
func (x Float32x8) Add(y Float32x8) Float32x8

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPS, CPU Feature: AVX512EVEX
func (x Float32x16) Add(y Float32x16) Float32x16

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPD, CPU Feature: AVX
func (x Float64x2) Add(y Float64x2) Float64x2

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPD, CPU Feature: AVX
func (x Float64x4) Add(y Float64x4) Float64x4

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPD, CPU Feature: AVX512EVEX
func (x Float64x8) Add(y Float64x8) Float64x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX
func (x Int8x16) Add(y Int8x16) Int8x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX2
func (x Int8x32) Add(y Int8x32) Int8x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Int8x64) Add(y Int8x64) Int8x64

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX
func (x Int16x8) Add(y Int16x8) Int16x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX2
func (x Int16x16) Add(y Int16x16) Int16x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Int16x32) Add(y Int16x32) Int16x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX
func (x Int32x4) Add(y Int32x4) Int32x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX2
func (x Int32x8) Add(y Int32x8) Int32x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Int32x16) Add(y Int32x16) Int32x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX
func (x Int64x2) Add(y Int64x2) Int64x2

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX2
func (x Int64x4) Add(y Int64x4) Int64x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Int64x8) Add(y Int64x8) Int64x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX
func (x Uint8x16) Add(y Uint8x16) Uint8x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX2
func (x Uint8x32) Add(y Uint8x32) Uint8x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Uint8x64) Add(y Uint8x64) Uint8x64

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX
func (x Uint16x8) Add(y Uint16x8) Uint16x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX2
func (x Uint16x16) Add(y Uint16x16) Uint16x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Uint16x32) Add(y Uint16x32) Uint16x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX
func (x Uint32x4) Add(y Uint32x4) Uint32x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX2
func (x Uint32x8) Add(y Uint32x8) Uint32x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Uint32x16) Add(y Uint32x16) Uint32x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX
func (x Uint64x2) Add(y Uint64x2) Uint64x2

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX2
func (x Uint64x4) Add(y Uint64x4) Uint64x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Add(y Uint64x8) Uint64x8

/* AddSub */

// AddSub subtracts even elements and adds odd elements of two vectors.
//
// Asm: VADDSUBPS, CPU Feature: AVX
func (x Float32x4) AddSub(y Float32x4) Float32x4

// AddSub subtracts even elements and adds odd elements of two vectors.
//
// Asm: VADDSUBPS, CPU Feature: AVX
func (x Float32x8) AddSub(y Float32x8) Float32x8

// AddSub subtracts even elements and adds odd elements of two vectors.
//
// Asm: VADDSUBPD, CPU Feature: AVX
func (x Float64x2) AddSub(y Float64x2) Float64x2

// AddSub subtracts even elements and adds odd elements of two vectors.
//
// Asm: VADDSUBPD, CPU Feature: AVX
func (x Float64x4) AddSub(y Float64x4) Float64x4

/* And */

// And performs a bitwise AND operation between two vectors.
//
// Asm: VANDPS, CPU Feature: AVX
func (x Float32x4) And(y Float32x4) Float32x4

// And performs a bitwise AND operation between two vectors.
//
// Asm: VANDPS, CPU Feature: AVX
func (x Float32x8) And(y Float32x8) Float32x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPS, CPU Feature: AVX512EVEX
func (x Float32x16) And(y Float32x16) Float32x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VANDPD, CPU Feature: AVX
func (x Float64x2) And(y Float64x2) Float64x2

// And performs a bitwise AND operation between two vectors.
//
// Asm: VANDPD, CPU Feature: AVX
func (x Float64x4) And(y Float64x4) Float64x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPD, CPU Feature: AVX512EVEX
func (x Float64x8) And(y Float64x8) Float64x8

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Int8x16) And(y Int8x16) Int8x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Int8x32) And(y Int8x32) Int8x32

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Int16x8) And(y Int16x8) Int16x8

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Int16x16) And(y Int16x16) Int16x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Int32x4) And(y Int32x4) Int32x4

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Int32x8) And(y Int32x8) Int32x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Int32x16) And(y Int32x16) Int32x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Int64x2) And(y Int64x2) Int64x2

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Int64x4) And(y Int64x4) Int64x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Int64x8) And(y Int64x8) Int64x8

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Uint8x16) And(y Uint8x16) Uint8x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Uint8x32) And(y Uint8x32) Uint8x32

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Uint16x8) And(y Uint16x8) Uint16x8

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Uint16x16) And(y Uint16x16) Uint16x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Uint32x4) And(y Uint32x4) Uint32x4

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Uint32x8) And(y Uint32x8) Uint32x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Uint32x16) And(y Uint32x16) Uint32x16

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX
func (x Uint64x2) And(y Uint64x2) Uint64x2

// And performs a bitwise AND operation between two vectors.
//
// Asm: VPAND, CPU Feature: AVX2
func (x Uint64x4) And(y Uint64x4) Uint64x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) And(y Uint64x8) Uint64x8

/* AndNot */

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPS, CPU Feature: AVX
func (x Float32x4) AndNot(y Float32x4) Float32x4

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPS, CPU Feature: AVX
func (x Float32x8) AndNot(y Float32x8) Float32x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPS, CPU Feature: AVX512EVEX
func (x Float32x16) AndNot(y Float32x16) Float32x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPD, CPU Feature: AVX
func (x Float64x2) AndNot(y Float64x2) Float64x2

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPD, CPU Feature: AVX
func (x Float64x4) AndNot(y Float64x4) Float64x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPD, CPU Feature: AVX512EVEX
func (x Float64x8) AndNot(y Float64x8) Float64x8

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Int8x16) AndNot(y Int8x16) Int8x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Int8x32) AndNot(y Int8x32) Int8x32

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Int16x8) AndNot(y Int16x8) Int16x8

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Int16x16) AndNot(y Int16x16) Int16x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Int32x4) AndNot(y Int32x4) Int32x4

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Int32x8) AndNot(y Int32x8) Int32x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Int32x16) AndNot(y Int32x16) Int32x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Int64x2) AndNot(y Int64x2) Int64x2

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Int64x4) AndNot(y Int64x4) Int64x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Int64x8) AndNot(y Int64x8) Int64x8

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Uint8x16) AndNot(y Uint8x16) Uint8x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Uint8x32) AndNot(y Uint8x32) Uint8x32

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Uint16x8) AndNot(y Uint16x8) Uint16x8

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Uint16x16) AndNot(y Uint16x16) Uint16x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Uint32x4) AndNot(y Uint32x4) Uint32x4

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Uint32x8) AndNot(y Uint32x8) Uint32x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Uint32x16) AndNot(y Uint32x16) Uint32x16

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX
func (x Uint64x2) AndNot(y Uint64x2) Uint64x2

// AndNot performs a bitwise AND NOT operation between two vectors.
//
// Asm: VPANDN, CPU Feature: AVX2
func (x Uint64x4) AndNot(y Uint64x4) Uint64x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Uint64x8) AndNot(y Uint64x8) Uint64x8

/* ApproximateReciprocal */

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PS, CPU Feature: AVX512EVEX
func (x Float32x4) ApproximateReciprocal() Float32x4

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PS, CPU Feature: AVX512EVEX
func (x Float32x8) ApproximateReciprocal() Float32x8

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PS, CPU Feature: AVX512EVEX
func (x Float32x16) ApproximateReciprocal() Float32x16

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PD, CPU Feature: AVX512EVEX
func (x Float64x2) ApproximateReciprocal() Float64x2

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PD, CPU Feature: AVX512EVEX
func (x Float64x4) ApproximateReciprocal() Float64x4

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PD, CPU Feature: AVX512EVEX
func (x Float64x8) ApproximateReciprocal() Float64x8

/* ApproximateReciprocalOfSqrt */

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRTPS, CPU Feature: AVX
func (x Float32x4) ApproximateReciprocalOfSqrt() Float32x4

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRTPS, CPU Feature: AVX
func (x Float32x8) ApproximateReciprocalOfSqrt() Float32x8

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PS, CPU Feature: AVX512EVEX
func (x Float32x16) ApproximateReciprocalOfSqrt() Float32x16

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PD, CPU Feature: AVX512EVEX
func (x Float64x2) ApproximateReciprocalOfSqrt() Float64x2

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PD, CPU Feature: AVX512EVEX
func (x Float64x4) ApproximateReciprocalOfSqrt() Float64x4

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PD, CPU Feature: AVX512EVEX
func (x Float64x8) ApproximateReciprocalOfSqrt() Float64x8

/* Average */

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGB, CPU Feature: AVX
func (x Uint8x16) Average(y Uint8x16) Uint8x16

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGB, CPU Feature: AVX2
func (x Uint8x32) Average(y Uint8x32) Uint8x32

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGB, CPU Feature: AVX512EVEX
func (x Uint8x64) Average(y Uint8x64) Uint8x64

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGW, CPU Feature: AVX
func (x Uint16x8) Average(y Uint16x8) Uint16x8

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGW, CPU Feature: AVX2
func (x Uint16x16) Average(y Uint16x16) Uint16x16

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGW, CPU Feature: AVX512EVEX
func (x Uint16x32) Average(y Uint16x32) Uint16x32

/* Ceil */

// Ceil rounds elements up to the nearest integer.
// Const Immediate = 2.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x4) Ceil() Float32x4

// Ceil rounds elements up to the nearest integer.
// Const Immediate = 2.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x8) Ceil() Float32x8

// Ceil rounds elements up to the nearest integer.
// Const Immediate = 2.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x2) Ceil() Float64x2

// Ceil rounds elements up to the nearest integer.
// Const Immediate = 2.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x4) Ceil() Float64x4

/* CeilSuppressExceptionWithPrecision */

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) CeilSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) CeilSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) CeilSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) CeilSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) CeilSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) CeilSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* CeilWithPrecision */

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) CeilWithPrecision(imm8 uint8) Float32x4

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) CeilWithPrecision(imm8 uint8) Float32x8

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) CeilWithPrecision(imm8 uint8) Float32x16

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) CeilWithPrecision(imm8 uint8) Float64x2

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) CeilWithPrecision(imm8 uint8) Float64x4

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) CeilWithPrecision(imm8 uint8) Float64x8

/* DiffWithCeilSuppressExceptionWithPrecision */

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithCeilSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithCeilSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithCeilSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithCeilSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithCeilSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithCeilSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* DiffWithCeilWithPrecision */

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithCeilWithPrecision(imm8 uint8) Float32x4

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithCeilWithPrecision(imm8 uint8) Float32x8

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithCeilWithPrecision(imm8 uint8) Float32x16

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithCeilWithPrecision(imm8 uint8) Float64x2

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithCeilWithPrecision(imm8 uint8) Float64x4

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithCeilWithPrecision(imm8 uint8) Float64x8

/* DiffWithFloorSuppressExceptionWithPrecision */

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithFloorSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithFloorSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithFloorSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithFloorSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithFloorSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithFloorSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* DiffWithFloorWithPrecision */

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithFloorWithPrecision(imm8 uint8) Float32x4

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithFloorWithPrecision(imm8 uint8) Float32x8

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithFloorWithPrecision(imm8 uint8) Float32x16

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithFloorWithPrecision(imm8 uint8) Float64x2

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithFloorWithPrecision(imm8 uint8) Float64x4

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithFloorWithPrecision(imm8 uint8) Float64x8

/* DiffWithRoundSuppressExceptionWithPrecision */

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithRoundSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithRoundSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithRoundSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithRoundSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithRoundSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithRoundSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* DiffWithRoundWithPrecision */

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithRoundWithPrecision(imm8 uint8) Float32x4

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithRoundWithPrecision(imm8 uint8) Float32x8

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithRoundWithPrecision(imm8 uint8) Float32x16

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithRoundWithPrecision(imm8 uint8) Float64x2

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithRoundWithPrecision(imm8 uint8) Float64x4

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithRoundWithPrecision(imm8 uint8) Float64x8

/* DiffWithTruncSuppressExceptionWithPrecision */

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithTruncSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithTruncSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithTruncSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithTruncSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithTruncSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithTruncSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* DiffWithTruncWithPrecision */

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) DiffWithTruncWithPrecision(imm8 uint8) Float32x4

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) DiffWithTruncWithPrecision(imm8 uint8) Float32x8

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) DiffWithTruncWithPrecision(imm8 uint8) Float32x16

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) DiffWithTruncWithPrecision(imm8 uint8) Float64x2

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) DiffWithTruncWithPrecision(imm8 uint8) Float64x4

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) DiffWithTruncWithPrecision(imm8 uint8) Float64x8

/* Div */

// Div divides elements of two vectors.
//
// Asm: VDIVPS, CPU Feature: AVX
func (x Float32x4) Div(y Float32x4) Float32x4

// Div divides elements of two vectors.
//
// Asm: VDIVPS, CPU Feature: AVX
func (x Float32x8) Div(y Float32x8) Float32x8

// Div divides elements of two vectors.
//
// Asm: VDIVPS, CPU Feature: AVX512EVEX
func (x Float32x16) Div(y Float32x16) Float32x16

// Div divides elements of two vectors.
//
// Asm: VDIVPD, CPU Feature: AVX
func (x Float64x2) Div(y Float64x2) Float64x2

// Div divides elements of two vectors.
//
// Asm: VDIVPD, CPU Feature: AVX
func (x Float64x4) Div(y Float64x4) Float64x4

// Div divides elements of two vectors.
//
// Asm: VDIVPD, CPU Feature: AVX512EVEX
func (x Float64x8) Div(y Float64x8) Float64x8

/* DotProdBroadcast */

// DotProdBroadcast multiplies all elements and broadcasts the sum.
// Const Immediate = 127.
//
// Asm: VDPPD, CPU Feature: AVX
func (x Float64x2) DotProdBroadcast(y Float64x2) Float64x2

/* Equal */

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQB, CPU Feature: AVX
func (x Int8x16) Equal(y Int8x16) Mask8x16

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQB, CPU Feature: AVX2
func (x Int8x32) Equal(y Int8x32) Mask8x32

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQW, CPU Feature: AVX
func (x Int16x8) Equal(y Int16x8) Mask16x8

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQW, CPU Feature: AVX2
func (x Int16x16) Equal(y Int16x16) Mask16x16

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQD, CPU Feature: AVX
func (x Int32x4) Equal(y Int32x4) Mask32x4

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQD, CPU Feature: AVX2
func (x Int32x8) Equal(y Int32x8) Mask32x8

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQQ, CPU Feature: AVX
func (x Int64x2) Equal(y Int64x2) Mask64x2

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VPCMPEQQ, CPU Feature: AVX2
func (x Int64x4) Equal(y Int64x4) Mask64x4

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) Equal(y Float32x4) Mask32x4

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) Equal(y Float32x8) Mask32x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) Equal(y Float32x16) Mask32x16

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) Equal(y Float64x2) Mask64x2

// Equal compares for equality.
// Const Immediate = 0.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) Equal(y Float64x4) Mask64x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) Equal(y Float64x8) Mask64x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) Equal(y Int8x64) Mask8x64

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) Equal(y Int16x32) Mask16x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) Equal(y Int32x16) Mask32x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) Equal(y Int64x8) Mask64x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) Equal(y Uint8x16) Mask8x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) Equal(y Uint8x32) Mask8x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) Equal(y Uint8x64) Mask8x64

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) Equal(y Uint16x8) Mask16x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) Equal(y Uint16x16) Mask16x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) Equal(y Uint16x32) Mask16x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) Equal(y Uint32x4) Mask32x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) Equal(y Uint32x8) Mask32x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) Equal(y Uint32x16) Mask32x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) Equal(y Uint64x2) Mask64x2

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) Equal(y Uint64x4) Mask64x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Equal(y Uint64x8) Mask64x8

/* Floor */

// Floor rounds elements down to the nearest integer.
// Const Immediate = 1.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x4) Floor() Float32x4

// Floor rounds elements down to the nearest integer.
// Const Immediate = 1.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x8) Floor() Float32x8

// Floor rounds elements down to the nearest integer.
// Const Immediate = 1.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x2) Floor() Float64x2

// Floor rounds elements down to the nearest integer.
// Const Immediate = 1.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x4) Floor() Float64x4

/* FloorSuppressExceptionWithPrecision */

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) FloorSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) FloorSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) FloorSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) FloorSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) FloorSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) FloorSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* FloorWithPrecision */

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) FloorWithPrecision(imm8 uint8) Float32x4

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) FloorWithPrecision(imm8 uint8) Float32x8

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) FloorWithPrecision(imm8 uint8) Float32x16

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) FloorWithPrecision(imm8 uint8) Float64x2

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) FloorWithPrecision(imm8 uint8) Float64x4

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) FloorWithPrecision(imm8 uint8) Float64x8

/* FusedMultiplyAdd */

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PS, CPU Feature: AVX512EVEX
func (x Float32x4) FusedMultiplyAdd(y Float32x4, z Float32x4) Float32x4

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PS, CPU Feature: AVX512EVEX
func (x Float32x8) FusedMultiplyAdd(y Float32x8, z Float32x8) Float32x8

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PS, CPU Feature: AVX512EVEX
func (x Float32x16) FusedMultiplyAdd(y Float32x16, z Float32x16) Float32x16

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PD, CPU Feature: AVX512EVEX
func (x Float64x2) FusedMultiplyAdd(y Float64x2, z Float64x2) Float64x2

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PD, CPU Feature: AVX512EVEX
func (x Float64x4) FusedMultiplyAdd(y Float64x4, z Float64x4) Float64x4

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PD, CPU Feature: AVX512EVEX
func (x Float64x8) FusedMultiplyAdd(y Float64x8, z Float64x8) Float64x8

/* FusedMultiplyAddSub */

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PS, CPU Feature: AVX512EVEX
func (x Float32x4) FusedMultiplyAddSub(y Float32x4, z Float32x4) Float32x4

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PS, CPU Feature: AVX512EVEX
func (x Float32x8) FusedMultiplyAddSub(y Float32x8, z Float32x8) Float32x8

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PS, CPU Feature: AVX512EVEX
func (x Float32x16) FusedMultiplyAddSub(y Float32x16, z Float32x16) Float32x16

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PD, CPU Feature: AVX512EVEX
func (x Float64x2) FusedMultiplyAddSub(y Float64x2, z Float64x2) Float64x2

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PD, CPU Feature: AVX512EVEX
func (x Float64x4) FusedMultiplyAddSub(y Float64x4, z Float64x4) Float64x4

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PD, CPU Feature: AVX512EVEX
func (x Float64x8) FusedMultiplyAddSub(y Float64x8, z Float64x8) Float64x8

/* FusedMultiplySubAdd */

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PS, CPU Feature: AVX512EVEX
func (x Float32x4) FusedMultiplySubAdd(y Float32x4, z Float32x4) Float32x4

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PS, CPU Feature: AVX512EVEX
func (x Float32x8) FusedMultiplySubAdd(y Float32x8, z Float32x8) Float32x8

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PS, CPU Feature: AVX512EVEX
func (x Float32x16) FusedMultiplySubAdd(y Float32x16, z Float32x16) Float32x16

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PD, CPU Feature: AVX512EVEX
func (x Float64x2) FusedMultiplySubAdd(y Float64x2, z Float64x2) Float64x2

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PD, CPU Feature: AVX512EVEX
func (x Float64x4) FusedMultiplySubAdd(y Float64x4, z Float64x4) Float64x4

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PD, CPU Feature: AVX512EVEX
func (x Float64x8) FusedMultiplySubAdd(y Float64x8, z Float64x8) Float64x8

/* GaloisFieldAffineTransform */

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8):
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEQB, CPU Feature: AVX512EVEX
func (x Uint8x16) GaloisFieldAffineTransform(y Uint64x2, b uint8) Uint8x16

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8):
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEQB, CPU Feature: AVX512EVEX
func (x Uint8x32) GaloisFieldAffineTransform(y Uint64x4, b uint8) Uint8x32

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8):
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEQB, CPU Feature: AVX512EVEX
func (x Uint8x64) GaloisFieldAffineTransform(y Uint64x8, b uint8) Uint8x64

/* GaloisFieldAffineTransformInversed */

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8),
// with x inversed with reduction polynomial x^8 + x^4 + x^3 + x + 1:
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEINVQB, CPU Feature: AVX512EVEX
func (x Uint8x16) GaloisFieldAffineTransformInversed(y Uint64x2, b uint8) Uint8x16

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8),
// with x inversed with reduction polynomial x^8 + x^4 + x^3 + x + 1:
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEINVQB, CPU Feature: AVX512EVEX
func (x Uint8x32) GaloisFieldAffineTransformInversed(y Uint64x4, b uint8) Uint8x32

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8),
// with x inversed with reduction polynomial x^8 + x^4 + x^3 + x + 1:
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEINVQB, CPU Feature: AVX512EVEX
func (x Uint8x64) GaloisFieldAffineTransformInversed(y Uint64x8, b uint8) Uint8x64

/* GaloisFieldMul */

// GaloisFieldMul computes element-wise GF(2^8) multiplication with
// reduction polynomial x^8 + x^4 + x^3 + x + 1.
//
// Asm: VGF2P8MULB, CPU Feature: AVX512EVEX
func (x Uint8x16) GaloisFieldMul(y Uint8x16) Uint8x16

// GaloisFieldMul computes element-wise GF(2^8) multiplication with
// reduction polynomial x^8 + x^4 + x^3 + x + 1.
//
// Asm: VGF2P8MULB, CPU Feature: AVX512EVEX
func (x Uint8x32) GaloisFieldMul(y Uint8x32) Uint8x32

// GaloisFieldMul computes element-wise GF(2^8) multiplication with
// reduction polynomial x^8 + x^4 + x^3 + x + 1.
//
// Asm: VGF2P8MULB, CPU Feature: AVX512EVEX
func (x Uint8x64) GaloisFieldMul(y Uint8x64) Uint8x64

/* GetElem */

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRB, CPU Feature: AVX512EVEX
func (x Int8x16) GetElem(imm8 uint8) int8

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRW, CPU Feature: AVX512EVEX
func (x Int16x8) GetElem(imm8 uint8) int16

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRD, CPU Feature: AVX
func (x Int32x4) GetElem(imm8 uint8) int32

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRQ, CPU Feature: AVX
func (x Int64x2) GetElem(imm8 uint8) int64

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRB, CPU Feature: AVX512EVEX
func (x Uint8x16) GetElem(imm8 uint8) uint8

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRW, CPU Feature: AVX512EVEX
func (x Uint16x8) GetElem(imm8 uint8) uint16

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRD, CPU Feature: AVX
func (x Uint32x4) GetElem(imm8 uint8) uint32

// GetElem retrieves a single constant-indexed element's value.
//
// Asm: VPEXTRQ, CPU Feature: AVX
func (x Uint64x2) GetElem(imm8 uint8) uint64

/* Greater */

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTB, CPU Feature: AVX
func (x Int8x16) Greater(y Int8x16) Mask8x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTB, CPU Feature: AVX2
func (x Int8x32) Greater(y Int8x32) Mask8x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTW, CPU Feature: AVX
func (x Int16x8) Greater(y Int16x8) Mask16x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTW, CPU Feature: AVX2
func (x Int16x16) Greater(y Int16x16) Mask16x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTD, CPU Feature: AVX
func (x Int32x4) Greater(y Int32x4) Mask32x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTD, CPU Feature: AVX2
func (x Int32x8) Greater(y Int32x8) Mask32x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPGTQ, CPU Feature: AVX2
func (x Int64x4) Greater(y Int64x4) Mask64x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) Greater(y Float32x4) Mask32x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) Greater(y Float32x8) Mask32x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) Greater(y Float32x16) Mask32x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) Greater(y Float64x2) Mask64x2

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) Greater(y Float64x4) Mask64x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) Greater(y Float64x8) Mask64x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) Greater(y Int8x64) Mask8x64

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) Greater(y Int16x32) Mask16x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) Greater(y Int32x16) Mask32x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) Greater(y Int64x2) Mask64x2

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) Greater(y Int64x8) Mask64x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) Greater(y Uint8x16) Mask8x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) Greater(y Uint8x32) Mask8x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) Greater(y Uint8x64) Mask8x64

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) Greater(y Uint16x8) Mask16x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) Greater(y Uint16x16) Mask16x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) Greater(y Uint16x32) Mask16x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) Greater(y Uint32x4) Mask32x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) Greater(y Uint32x8) Mask32x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) Greater(y Uint32x16) Mask32x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) Greater(y Uint64x2) Mask64x2

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) Greater(y Uint64x4) Mask64x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Greater(y Uint64x8) Mask64x8

/* GreaterEqual */

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) GreaterEqual(y Float32x4) Mask32x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) GreaterEqual(y Float32x8) Mask32x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) GreaterEqual(y Float32x16) Mask32x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) GreaterEqual(y Float64x2) Mask64x2

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) GreaterEqual(y Float64x4) Mask64x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) GreaterEqual(y Float64x8) Mask64x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) GreaterEqual(y Int8x16) Mask8x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) GreaterEqual(y Int8x32) Mask8x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) GreaterEqual(y Int8x64) Mask8x64

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) GreaterEqual(y Int16x8) Mask16x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) GreaterEqual(y Int16x16) Mask16x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) GreaterEqual(y Int16x32) Mask16x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) GreaterEqual(y Int32x4) Mask32x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) GreaterEqual(y Int32x8) Mask32x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) GreaterEqual(y Int32x16) Mask32x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) GreaterEqual(y Int64x2) Mask64x2

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) GreaterEqual(y Int64x4) Mask64x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) GreaterEqual(y Int64x8) Mask64x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) GreaterEqual(y Uint8x16) Mask8x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) GreaterEqual(y Uint8x32) Mask8x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) GreaterEqual(y Uint8x64) Mask8x64

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) GreaterEqual(y Uint16x8) Mask16x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) GreaterEqual(y Uint16x16) Mask16x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) GreaterEqual(y Uint16x32) Mask16x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) GreaterEqual(y Uint32x4) Mask32x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) GreaterEqual(y Uint32x8) Mask32x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) GreaterEqual(y Uint32x16) Mask32x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) GreaterEqual(y Uint64x2) Mask64x2

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) GreaterEqual(y Uint64x4) Mask64x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) GreaterEqual(y Uint64x8) Mask64x8

/* IsNan */

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) IsNan(y Float32x4) Mask32x4

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) IsNan(y Float32x8) Mask32x8

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) IsNan(y Float32x16) Mask32x16

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) IsNan(y Float64x2) Mask64x2

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) IsNan(y Float64x4) Mask64x4

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) IsNan(y Float64x8) Mask64x8

/* Less */

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) Less(y Float32x4) Mask32x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) Less(y Float32x8) Mask32x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) Less(y Float32x16) Mask32x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) Less(y Float64x2) Mask64x2

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) Less(y Float64x4) Mask64x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) Less(y Float64x8) Mask64x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) Less(y Int8x16) Mask8x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) Less(y Int8x32) Mask8x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) Less(y Int8x64) Mask8x64

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) Less(y Int16x8) Mask16x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) Less(y Int16x16) Mask16x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) Less(y Int16x32) Mask16x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) Less(y Int32x4) Mask32x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) Less(y Int32x8) Mask32x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) Less(y Int32x16) Mask32x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) Less(y Int64x2) Mask64x2

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) Less(y Int64x4) Mask64x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) Less(y Int64x8) Mask64x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) Less(y Uint8x16) Mask8x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) Less(y Uint8x32) Mask8x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) Less(y Uint8x64) Mask8x64

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) Less(y Uint16x8) Mask16x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) Less(y Uint16x16) Mask16x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) Less(y Uint16x32) Mask16x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) Less(y Uint32x4) Mask32x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) Less(y Uint32x8) Mask32x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) Less(y Uint32x16) Mask32x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) Less(y Uint64x2) Mask64x2

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) Less(y Uint64x4) Mask64x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Less(y Uint64x8) Mask64x8

/* LessEqual */

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) LessEqual(y Float32x4) Mask32x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) LessEqual(y Float32x8) Mask32x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) LessEqual(y Float32x16) Mask32x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) LessEqual(y Float64x2) Mask64x2

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) LessEqual(y Float64x4) Mask64x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) LessEqual(y Float64x8) Mask64x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) LessEqual(y Int8x16) Mask8x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) LessEqual(y Int8x32) Mask8x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) LessEqual(y Int8x64) Mask8x64

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) LessEqual(y Int16x8) Mask16x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) LessEqual(y Int16x16) Mask16x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) LessEqual(y Int16x32) Mask16x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) LessEqual(y Int32x4) Mask32x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) LessEqual(y Int32x8) Mask32x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) LessEqual(y Int32x16) Mask32x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) LessEqual(y Int64x2) Mask64x2

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) LessEqual(y Int64x4) Mask64x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) LessEqual(y Int64x8) Mask64x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) LessEqual(y Uint8x16) Mask8x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) LessEqual(y Uint8x32) Mask8x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) LessEqual(y Uint8x64) Mask8x64

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) LessEqual(y Uint16x8) Mask16x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) LessEqual(y Uint16x16) Mask16x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) LessEqual(y Uint16x32) Mask16x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) LessEqual(y Uint32x4) Mask32x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) LessEqual(y Uint32x8) Mask32x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) LessEqual(y Uint32x16) Mask32x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) LessEqual(y Uint64x2) Mask64x2

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) LessEqual(y Uint64x4) Mask64x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) LessEqual(y Uint64x8) Mask64x8

/* MaskedAbsolute */

// Absolute computes the absolute value of each element.
//
// Asm: VPABSB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedAbsolute(y Mask8x16) Int8x16

// Absolute computes the absolute value of each element.
//
// Asm: VPABSB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedAbsolute(y Mask8x32) Int8x32

// Absolute computes the absolute value of each element.
//
// Asm: VPABSB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedAbsolute(y Mask8x64) Int8x64

// Absolute computes the absolute value of each element.
//
// Asm: VPABSW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedAbsolute(y Mask16x8) Int16x8

// Absolute computes the absolute value of each element.
//
// Asm: VPABSW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedAbsolute(y Mask16x16) Int16x16

// Absolute computes the absolute value of each element.
//
// Asm: VPABSW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedAbsolute(y Mask16x32) Int16x32

// Absolute computes the absolute value of each element.
//
// Asm: VPABSD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedAbsolute(y Mask32x4) Int32x4

// Absolute computes the absolute value of each element.
//
// Asm: VPABSD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedAbsolute(y Mask32x8) Int32x8

// Absolute computes the absolute value of each element.
//
// Asm: VPABSD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedAbsolute(y Mask32x16) Int32x16

// Absolute computes the absolute value of each element.
//
// Asm: VPABSQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedAbsolute(y Mask64x2) Int64x2

// Absolute computes the absolute value of each element.
//
// Asm: VPABSQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedAbsolute(y Mask64x4) Int64x4

// Absolute computes the absolute value of each element.
//
// Asm: VPABSQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedAbsolute(y Mask64x8) Int64x8

/* MaskedAdd */

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedAdd(y Float32x4, z Mask32x4) Float32x4

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedAdd(y Float32x8, z Mask32x8) Float32x8

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedAdd(y Float32x16, z Mask32x16) Float32x16

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedAdd(y Float64x2, z Mask64x2) Float64x2

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedAdd(y Float64x4, z Mask64x4) Float64x4

// Add adds corresponding elements of two vectors.
//
// Asm: VADDPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedAdd(y Float64x8, z Mask64x8) Float64x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedAdd(y Int8x16, z Mask8x16) Int8x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedAdd(y Int8x32, z Mask8x32) Int8x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedAdd(y Int8x64, z Mask8x64) Int8x64

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedAdd(y Int16x8, z Mask16x8) Int16x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedAdd(y Int16x16, z Mask16x16) Int16x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedAdd(y Int16x32, z Mask16x32) Int16x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedAdd(y Int32x4, z Mask32x4) Int32x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedAdd(y Int32x8, z Mask32x8) Int32x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedAdd(y Int32x16, z Mask32x16) Int32x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedAdd(y Int64x2, z Mask64x2) Int64x2

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedAdd(y Int64x4, z Mask64x4) Int64x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedAdd(y Int64x8, z Mask64x8) Int64x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedAdd(y Uint8x16, z Mask8x16) Uint8x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedAdd(y Uint8x32, z Mask8x32) Uint8x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedAdd(y Uint8x64, z Mask8x64) Uint8x64

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedAdd(y Uint16x8, z Mask16x8) Uint16x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedAdd(y Uint16x16, z Mask16x16) Uint16x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedAdd(y Uint16x32, z Mask16x32) Uint16x32

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedAdd(y Uint32x4, z Mask32x4) Uint32x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedAdd(y Uint32x8, z Mask32x8) Uint32x8

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedAdd(y Uint32x16, z Mask32x16) Uint32x16

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedAdd(y Uint64x2, z Mask64x2) Uint64x2

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedAdd(y Uint64x4, z Mask64x4) Uint64x4

// Add adds corresponding elements of two vectors.
//
// Asm: VPADDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedAdd(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedAnd */

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedAnd(y Float32x4, z Mask32x4) Float32x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedAnd(y Float32x8, z Mask32x8) Float32x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedAnd(y Float32x16, z Mask32x16) Float32x16

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedAnd(y Float64x2, z Mask64x2) Float64x2

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedAnd(y Float64x4, z Mask64x4) Float64x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VANDPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedAnd(y Float64x8, z Mask64x8) Float64x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedAnd(y Int32x4, z Mask32x4) Int32x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedAnd(y Int32x8, z Mask32x8) Int32x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedAnd(y Int32x16, z Mask32x16) Int32x16

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedAnd(y Int64x2, z Mask64x2) Int64x2

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedAnd(y Int64x4, z Mask64x4) Int64x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedAnd(y Int64x8, z Mask64x8) Int64x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedAnd(y Uint32x4, z Mask32x4) Uint32x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedAnd(y Uint32x8, z Mask32x8) Uint32x8

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedAnd(y Uint32x16, z Mask32x16) Uint32x16

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedAnd(y Uint64x2, z Mask64x2) Uint64x2

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedAnd(y Uint64x4, z Mask64x4) Uint64x4

// And performs a masked bitwise AND operation between two vectors.
//
// Asm: VPANDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedAnd(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedAndNot */

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedAndNot(y Float32x4, z Mask32x4) Float32x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedAndNot(y Float32x8, z Mask32x8) Float32x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedAndNot(y Float32x16, z Mask32x16) Float32x16

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedAndNot(y Float64x2, z Mask64x2) Float64x2

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedAndNot(y Float64x4, z Mask64x4) Float64x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VANDNPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedAndNot(y Float64x8, z Mask64x8) Float64x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedAndNot(y Int32x4, z Mask32x4) Int32x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedAndNot(y Int32x8, z Mask32x8) Int32x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedAndNot(y Int32x16, z Mask32x16) Int32x16

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedAndNot(y Int64x2, z Mask64x2) Int64x2

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedAndNot(y Int64x4, z Mask64x4) Int64x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedAndNot(y Int64x8, z Mask64x8) Int64x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedAndNot(y Uint32x4, z Mask32x4) Uint32x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedAndNot(y Uint32x8, z Mask32x8) Uint32x8

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDND, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedAndNot(y Uint32x16, z Mask32x16) Uint32x16

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedAndNot(y Uint64x2, z Mask64x2) Uint64x2

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedAndNot(y Uint64x4, z Mask64x4) Uint64x4

// AndNot performs a masked bitwise AND NOT operation between two vectors.
//
// Asm: VPANDNQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedAndNot(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedApproximateReciprocal */

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedApproximateReciprocal(y Mask32x4) Float32x4

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedApproximateReciprocal(y Mask32x8) Float32x8

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedApproximateReciprocal(y Mask32x16) Float32x16

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedApproximateReciprocal(y Mask64x2) Float64x2

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedApproximateReciprocal(y Mask64x4) Float64x4

// ApproximateReciprocal computes an approximate reciprocal of each element.
//
// Asm: VRCP14PD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedApproximateReciprocal(y Mask64x8) Float64x8

/* MaskedApproximateReciprocalOfSqrt */

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedApproximateReciprocalOfSqrt(y Mask32x4) Float32x4

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedApproximateReciprocalOfSqrt(y Mask32x8) Float32x8

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedApproximateReciprocalOfSqrt(y Mask32x16) Float32x16

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedApproximateReciprocalOfSqrt(y Mask64x2) Float64x2

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedApproximateReciprocalOfSqrt(y Mask64x4) Float64x4

// ApproximateReciprocalOfSqrt computes an approximate reciprocal of the square root of each element.
//
// Asm: VRSQRT14PD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedApproximateReciprocalOfSqrt(y Mask64x8) Float64x8

/* MaskedAverage */

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedAverage(y Uint8x16, z Mask8x16) Uint8x16

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedAverage(y Uint8x32, z Mask8x32) Uint8x32

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedAverage(y Uint8x64, z Mask8x64) Uint8x64

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedAverage(y Uint16x8, z Mask16x8) Uint16x8

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedAverage(y Uint16x16, z Mask16x16) Uint16x16

// Average computes the rounded average of corresponding elements.
//
// Asm: VPAVGW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedAverage(y Uint16x32, z Mask16x32) Uint16x32

/* MaskedCeilSuppressExceptionWithPrecision */

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedCeilSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedCeilSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedCeilSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedCeilSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedCeilSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// CeilSuppressExceptionWithPrecision rounds elements up with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedCeilSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedCeilWithPrecision */

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedCeilWithPrecision(imm uint8, y Mask32x4) Float32x4

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedCeilWithPrecision(imm uint8, y Mask32x8) Float32x8

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedCeilWithPrecision(imm uint8, y Mask32x16) Float32x16

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedCeilWithPrecision(imm uint8, y Mask64x2) Float64x2

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedCeilWithPrecision(imm uint8, y Mask64x4) Float64x4

// CeilWithPrecision rounds elements up with specified precision, masked.
// Const Immediate = 2.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedCeilWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithCeilSuppressExceptionWithPrecision */

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithCeilSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithCeilSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithCeilSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithCeilSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithCeilSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithCeilSuppressExceptionWithPrecision computes the difference after ceiling with specified precision, suppressing exceptions.
// Const Immediate = 10.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithCeilSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithCeilWithPrecision */

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithCeilWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithCeilWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithCeilWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithCeilWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithCeilWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithCeilWithPrecision computes the difference after ceiling with specified precision.
// Const Immediate = 2.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithCeilWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithFloorSuppressExceptionWithPrecision */

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithFloorSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithFloorSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithFloorSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithFloorSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithFloorSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithFloorSuppressExceptionWithPrecision computes the difference after flooring with specified precision, suppressing exceptions.
// Const Immediate = 9.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithFloorSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithFloorWithPrecision */

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithFloorWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithFloorWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithFloorWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithFloorWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithFloorWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithFloorWithPrecision computes the difference after flooring with specified precision.
// Const Immediate = 1.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithFloorWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithRoundSuppressExceptionWithPrecision */

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithRoundSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithRoundSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithRoundSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithRoundSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithRoundSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithRoundSuppressExceptionWithPrecision computes the difference after rounding with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithRoundSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithRoundWithPrecision */

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithRoundWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithRoundWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithRoundWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithRoundWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithRoundWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithRoundWithPrecision computes the difference after rounding with specified precision.
// Const Immediate = 0.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithRoundWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithTruncSuppressExceptionWithPrecision */

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithTruncSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithTruncSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithTruncSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithTruncSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithTruncSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithTruncSuppressExceptionWithPrecision computes the difference after truncating with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithTruncSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiffWithTruncWithPrecision */

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiffWithTruncWithPrecision(imm uint8, y Mask32x4) Float32x4

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiffWithTruncWithPrecision(imm uint8, y Mask32x8) Float32x8

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiffWithTruncWithPrecision(imm uint8, y Mask32x16) Float32x16

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiffWithTruncWithPrecision(imm uint8, y Mask64x2) Float64x2

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiffWithTruncWithPrecision(imm uint8, y Mask64x4) Float64x4

// DiffWithTruncWithPrecision computes the difference after truncating with specified precision.
// Const Immediate = 3.
//
// Asm: VREDUCEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiffWithTruncWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedDiv */

// Div divides elements of two vectors.
//
// Asm: VDIVPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedDiv(y Float32x4, z Mask32x4) Float32x4

// Div divides elements of two vectors.
//
// Asm: VDIVPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedDiv(y Float32x8, z Mask32x8) Float32x8

// Div divides elements of two vectors.
//
// Asm: VDIVPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedDiv(y Float32x16, z Mask32x16) Float32x16

// Div divides elements of two vectors.
//
// Asm: VDIVPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedDiv(y Float64x2, z Mask64x2) Float64x2

// Div divides elements of two vectors.
//
// Asm: VDIVPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedDiv(y Float64x4, z Mask64x4) Float64x4

// Div divides elements of two vectors.
//
// Asm: VDIVPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedDiv(y Float64x8, z Mask64x8) Float64x8

/* MaskedEqual */

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedEqual(y Float32x4, z Mask32x4) Mask32x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedEqual(y Float32x8, z Mask32x8) Mask32x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedEqual(y Float32x16, z Mask32x16) Mask32x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedEqual(y Float64x2, z Mask64x2) Mask64x2

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedEqual(y Float64x4, z Mask64x4) Mask64x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedEqual(y Float64x8, z Mask64x8) Mask64x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedEqual(y Int8x16, z Mask8x16) Mask8x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedEqual(y Int8x32, z Mask8x32) Mask8x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedEqual(y Int8x64, z Mask8x64) Mask8x64

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedEqual(y Int16x8, z Mask16x8) Mask16x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedEqual(y Int16x16, z Mask16x16) Mask16x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedEqual(y Int16x32, z Mask16x32) Mask16x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedEqual(y Int32x4, z Mask32x4) Mask32x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedEqual(y Int32x8, z Mask32x8) Mask32x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedEqual(y Int32x16, z Mask32x16) Mask32x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedEqual(y Int64x2, z Mask64x2) Mask64x2

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedEqual(y Int64x4, z Mask64x4) Mask64x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedEqual(y Int64x8, z Mask64x8) Mask64x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedEqual(y Uint8x16, z Mask8x16) Mask8x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedEqual(y Uint8x32, z Mask8x32) Mask8x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedEqual(y Uint8x64, z Mask8x64) Mask8x64

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedEqual(y Uint16x8, z Mask16x8) Mask16x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedEqual(y Uint16x16, z Mask16x16) Mask16x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedEqual(y Uint16x32, z Mask16x32) Mask16x32

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedEqual(y Uint32x4, z Mask32x4) Mask32x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedEqual(y Uint32x8, z Mask32x8) Mask32x8

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedEqual(y Uint32x16, z Mask32x16) Mask32x16

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedEqual(y Uint64x2, z Mask64x2) Mask64x2

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedEqual(y Uint64x4, z Mask64x4) Mask64x4

// Equal compares for equality, masked.
// Const Immediate = 0.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedEqual(y Uint64x8, z Mask64x8) Mask64x8

/* MaskedFloorSuppressExceptionWithPrecision */

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedFloorSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedFloorSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedFloorSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedFloorSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedFloorSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// FloorSuppressExceptionWithPrecision rounds elements down with specified precision, suppressing exceptions, masked.
// Const Immediate = 9.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedFloorSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedFloorWithPrecision */

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedFloorWithPrecision(imm uint8, y Mask32x4) Float32x4

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedFloorWithPrecision(imm uint8, y Mask32x8) Float32x8

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedFloorWithPrecision(imm uint8, y Mask32x16) Float32x16

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedFloorWithPrecision(imm uint8, y Mask64x2) Float64x2

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedFloorWithPrecision(imm uint8, y Mask64x4) Float64x4

// FloorWithPrecision rounds elements down with specified precision, masked.
// Const Immediate = 1.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedFloorWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedFusedMultiplyAdd */

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedFusedMultiplyAdd(y Float32x4, z Float32x4, u Mask32x4) Float32x4

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedFusedMultiplyAdd(y Float32x8, z Float32x8, u Mask32x8) Float32x8

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedFusedMultiplyAdd(y Float32x16, z Float32x16, u Mask32x16) Float32x16

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedFusedMultiplyAdd(y Float64x2, z Float64x2, u Mask64x2) Float64x2

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedFusedMultiplyAdd(y Float64x4, z Float64x4, u Mask64x4) Float64x4

// FusedMultiplyAdd performs `(v1 * v2) + v3`.
//
// Asm: VFMADD213PD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedFusedMultiplyAdd(y Float64x8, z Float64x8, u Mask64x8) Float64x8

/* MaskedFusedMultiplyAddSub */

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedFusedMultiplyAddSub(y Float32x4, z Float32x4, u Mask32x4) Float32x4

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedFusedMultiplyAddSub(y Float32x8, z Float32x8, u Mask32x8) Float32x8

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedFusedMultiplyAddSub(y Float32x16, z Float32x16, u Mask32x16) Float32x16

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedFusedMultiplyAddSub(y Float64x2, z Float64x2, u Mask64x2) Float64x2

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedFusedMultiplyAddSub(y Float64x4, z Float64x4, u Mask64x4) Float64x4

// FusedMultiplyAddSub performs `(v1 * v2) - v3` for odd-indexed elements, and `(v1 * v2) + v3` for even-indexed elements.
//
// Asm: VFMADDSUB213PD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedFusedMultiplyAddSub(y Float64x8, z Float64x8, u Mask64x8) Float64x8

/* MaskedFusedMultiplySubAdd */

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedFusedMultiplySubAdd(y Float32x4, z Float32x4, u Mask32x4) Float32x4

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedFusedMultiplySubAdd(y Float32x8, z Float32x8, u Mask32x8) Float32x8

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedFusedMultiplySubAdd(y Float32x16, z Float32x16, u Mask32x16) Float32x16

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedFusedMultiplySubAdd(y Float64x2, z Float64x2, u Mask64x2) Float64x2

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedFusedMultiplySubAdd(y Float64x4, z Float64x4, u Mask64x4) Float64x4

// FusedMultiplySubAdd performs `(v1 * v2) + v3` for odd-indexed elements, and `(v1 * v2) - v3` for even-indexed elements.
//
// Asm: VFMSUBADD213PD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedFusedMultiplySubAdd(y Float64x8, z Float64x8, u Mask64x8) Float64x8

/* MaskedGaloisFieldAffineTransform */

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8):
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEQB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedGaloisFieldAffineTransform(y Uint64x2, b uint8, m Mask8x16) Uint8x16

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8):
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEQB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedGaloisFieldAffineTransform(y Uint64x4, b uint8, m Mask8x32) Uint8x32

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8):
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEQB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedGaloisFieldAffineTransform(y Uint64x8, b uint8, m Mask8x64) Uint8x64

/* MaskedGaloisFieldAffineTransformInversed */

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8),
// with x inversed with reduction polynomial x^8 + x^4 + x^3 + x + 1:
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEINVQB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedGaloisFieldAffineTransformInversed(y Uint64x2, b uint8, m Mask8x16) Uint8x16

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8),
// with x inversed with reduction polynomial x^8 + x^4 + x^3 + x + 1:
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEINVQB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedGaloisFieldAffineTransformInversed(y Uint64x4, b uint8, m Mask8x32) Uint8x32

// GaloisFieldAffineTransform computes an affine transformation in GF(2^8),
// with x inversed with reduction polynomial x^8 + x^4 + x^3 + x + 1:
// x is a vector of 8-bit vectors, with each adjacent 8 as a group; y is a vector of 8x8 1-bit matrixes;
// b is an 8-bit vector. The affine transformation is y * x + b, with each element of y
// corresponding to a group of 8 elements in x.
//
// Asm: VGF2P8AFFINEINVQB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedGaloisFieldAffineTransformInversed(y Uint64x8, b uint8, m Mask8x64) Uint8x64

/* MaskedGaloisFieldMul */

// GaloisFieldMul computes element-wise GF(2^8) multiplication with
// reduction polynomial x^8 + x^4 + x^3 + x + 1.
//
// Asm: VGF2P8MULB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedGaloisFieldMul(y Uint8x16, z Mask8x16) Uint8x16

// GaloisFieldMul computes element-wise GF(2^8) multiplication with
// reduction polynomial x^8 + x^4 + x^3 + x + 1.
//
// Asm: VGF2P8MULB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedGaloisFieldMul(y Uint8x32, z Mask8x32) Uint8x32

// GaloisFieldMul computes element-wise GF(2^8) multiplication with
// reduction polynomial x^8 + x^4 + x^3 + x + 1.
//
// Asm: VGF2P8MULB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedGaloisFieldMul(y Uint8x64, z Mask8x64) Uint8x64

/* MaskedGreater */

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedGreater(y Float32x4, z Mask32x4) Mask32x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedGreater(y Float32x8, z Mask32x8) Mask32x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedGreater(y Float32x16, z Mask32x16) Mask32x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedGreater(y Float64x2, z Mask64x2) Mask64x2

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedGreater(y Float64x4, z Mask64x4) Mask64x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedGreater(y Float64x8, z Mask64x8) Mask64x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedGreater(y Int8x16, z Mask8x16) Mask8x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedGreater(y Int8x32, z Mask8x32) Mask8x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedGreater(y Int8x64, z Mask8x64) Mask8x64

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedGreater(y Int16x8, z Mask16x8) Mask16x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedGreater(y Int16x16, z Mask16x16) Mask16x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedGreater(y Int16x32, z Mask16x32) Mask16x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedGreater(y Int32x4, z Mask32x4) Mask32x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedGreater(y Int32x8, z Mask32x8) Mask32x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedGreater(y Int32x16, z Mask32x16) Mask32x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedGreater(y Int64x2, z Mask64x2) Mask64x2

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedGreater(y Int64x4, z Mask64x4) Mask64x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedGreater(y Int64x8, z Mask64x8) Mask64x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedGreater(y Uint8x16, z Mask8x16) Mask8x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedGreater(y Uint8x32, z Mask8x32) Mask8x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedGreater(y Uint8x64, z Mask8x64) Mask8x64

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedGreater(y Uint16x8, z Mask16x8) Mask16x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedGreater(y Uint16x16, z Mask16x16) Mask16x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedGreater(y Uint16x32, z Mask16x32) Mask16x32

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedGreater(y Uint32x4, z Mask32x4) Mask32x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedGreater(y Uint32x8, z Mask32x8) Mask32x8

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedGreater(y Uint32x16, z Mask32x16) Mask32x16

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedGreater(y Uint64x2, z Mask64x2) Mask64x2

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedGreater(y Uint64x4, z Mask64x4) Mask64x4

// Greater compares for greater than.
// Const Immediate = 6.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedGreater(y Uint64x8, z Mask64x8) Mask64x8

/* MaskedGreaterEqual */

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedGreaterEqual(y Float32x4, z Mask32x4) Mask32x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedGreaterEqual(y Float32x8, z Mask32x8) Mask32x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedGreaterEqual(y Float32x16, z Mask32x16) Mask32x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedGreaterEqual(y Float64x2, z Mask64x2) Mask64x2

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedGreaterEqual(y Float64x4, z Mask64x4) Mask64x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedGreaterEqual(y Float64x8, z Mask64x8) Mask64x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedGreaterEqual(y Int8x16, z Mask8x16) Mask8x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedGreaterEqual(y Int8x32, z Mask8x32) Mask8x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedGreaterEqual(y Int8x64, z Mask8x64) Mask8x64

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedGreaterEqual(y Int16x8, z Mask16x8) Mask16x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedGreaterEqual(y Int16x16, z Mask16x16) Mask16x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedGreaterEqual(y Int16x32, z Mask16x32) Mask16x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedGreaterEqual(y Int32x4, z Mask32x4) Mask32x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedGreaterEqual(y Int32x8, z Mask32x8) Mask32x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedGreaterEqual(y Int32x16, z Mask32x16) Mask32x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedGreaterEqual(y Int64x2, z Mask64x2) Mask64x2

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedGreaterEqual(y Int64x4, z Mask64x4) Mask64x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedGreaterEqual(y Int64x8, z Mask64x8) Mask64x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedGreaterEqual(y Uint8x16, z Mask8x16) Mask8x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedGreaterEqual(y Uint8x32, z Mask8x32) Mask8x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedGreaterEqual(y Uint8x64, z Mask8x64) Mask8x64

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedGreaterEqual(y Uint16x8, z Mask16x8) Mask16x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedGreaterEqual(y Uint16x16, z Mask16x16) Mask16x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedGreaterEqual(y Uint16x32, z Mask16x32) Mask16x32

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedGreaterEqual(y Uint32x4, z Mask32x4) Mask32x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedGreaterEqual(y Uint32x8, z Mask32x8) Mask32x8

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedGreaterEqual(y Uint32x16, z Mask32x16) Mask32x16

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedGreaterEqual(y Uint64x2, z Mask64x2) Mask64x2

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedGreaterEqual(y Uint64x4, z Mask64x4) Mask64x4

// GreaterEqual compares for greater than or equal.
// Const Immediate = 5.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedGreaterEqual(y Uint64x8, z Mask64x8) Mask64x8

/* MaskedIsNan */

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedIsNan(y Float32x4, z Mask32x4) Mask32x4

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedIsNan(y Float32x8, z Mask32x8) Mask32x8

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedIsNan(y Float32x16, z Mask32x16) Mask32x16

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedIsNan(y Float64x2, z Mask64x2) Mask64x2

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedIsNan(y Float64x4, z Mask64x4) Mask64x4

// IsNan checks if elements are NaN. Use as x.IsNan(x).
// Const Immediate = 3.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedIsNan(y Float64x8, z Mask64x8) Mask64x8

/* MaskedLess */

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedLess(y Float32x4, z Mask32x4) Mask32x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedLess(y Float32x8, z Mask32x8) Mask32x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedLess(y Float32x16, z Mask32x16) Mask32x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedLess(y Float64x2, z Mask64x2) Mask64x2

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedLess(y Float64x4, z Mask64x4) Mask64x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedLess(y Float64x8, z Mask64x8) Mask64x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedLess(y Int8x16, z Mask8x16) Mask8x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedLess(y Int8x32, z Mask8x32) Mask8x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedLess(y Int8x64, z Mask8x64) Mask8x64

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedLess(y Int16x8, z Mask16x8) Mask16x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedLess(y Int16x16, z Mask16x16) Mask16x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedLess(y Int16x32, z Mask16x32) Mask16x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedLess(y Int32x4, z Mask32x4) Mask32x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedLess(y Int32x8, z Mask32x8) Mask32x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedLess(y Int32x16, z Mask32x16) Mask32x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedLess(y Int64x2, z Mask64x2) Mask64x2

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedLess(y Int64x4, z Mask64x4) Mask64x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedLess(y Int64x8, z Mask64x8) Mask64x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedLess(y Uint8x16, z Mask8x16) Mask8x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedLess(y Uint8x32, z Mask8x32) Mask8x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedLess(y Uint8x64, z Mask8x64) Mask8x64

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedLess(y Uint16x8, z Mask16x8) Mask16x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedLess(y Uint16x16, z Mask16x16) Mask16x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedLess(y Uint16x32, z Mask16x32) Mask16x32

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedLess(y Uint32x4, z Mask32x4) Mask32x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedLess(y Uint32x8, z Mask32x8) Mask32x8

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedLess(y Uint32x16, z Mask32x16) Mask32x16

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedLess(y Uint64x2, z Mask64x2) Mask64x2

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedLess(y Uint64x4, z Mask64x4) Mask64x4

// Less compares for less than.
// Const Immediate = 1.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedLess(y Uint64x8, z Mask64x8) Mask64x8

/* MaskedLessEqual */

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedLessEqual(y Float32x4, z Mask32x4) Mask32x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedLessEqual(y Float32x8, z Mask32x8) Mask32x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedLessEqual(y Float32x16, z Mask32x16) Mask32x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedLessEqual(y Float64x2, z Mask64x2) Mask64x2

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedLessEqual(y Float64x4, z Mask64x4) Mask64x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedLessEqual(y Float64x8, z Mask64x8) Mask64x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedLessEqual(y Int8x16, z Mask8x16) Mask8x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedLessEqual(y Int8x32, z Mask8x32) Mask8x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedLessEqual(y Int8x64, z Mask8x64) Mask8x64

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedLessEqual(y Int16x8, z Mask16x8) Mask16x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedLessEqual(y Int16x16, z Mask16x16) Mask16x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedLessEqual(y Int16x32, z Mask16x32) Mask16x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedLessEqual(y Int32x4, z Mask32x4) Mask32x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedLessEqual(y Int32x8, z Mask32x8) Mask32x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedLessEqual(y Int32x16, z Mask32x16) Mask32x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedLessEqual(y Int64x2, z Mask64x2) Mask64x2

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedLessEqual(y Int64x4, z Mask64x4) Mask64x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedLessEqual(y Int64x8, z Mask64x8) Mask64x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedLessEqual(y Uint8x16, z Mask8x16) Mask8x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedLessEqual(y Uint8x32, z Mask8x32) Mask8x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedLessEqual(y Uint8x64, z Mask8x64) Mask8x64

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedLessEqual(y Uint16x8, z Mask16x8) Mask16x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedLessEqual(y Uint16x16, z Mask16x16) Mask16x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedLessEqual(y Uint16x32, z Mask16x32) Mask16x32

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedLessEqual(y Uint32x4, z Mask32x4) Mask32x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedLessEqual(y Uint32x8, z Mask32x8) Mask32x8

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedLessEqual(y Uint32x16, z Mask32x16) Mask32x16

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedLessEqual(y Uint64x2, z Mask64x2) Mask64x2

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedLessEqual(y Uint64x4, z Mask64x4) Mask64x4

// LessEqual compares for less than or equal.
// Const Immediate = 2.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedLessEqual(y Uint64x8, z Mask64x8) Mask64x8

/* MaskedMax */

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedMax(y Float32x4, z Mask32x4) Float32x4

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedMax(y Float32x8, z Mask32x8) Float32x8

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedMax(y Float32x16, z Mask32x16) Float32x16

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedMax(y Float64x2, z Mask64x2) Float64x2

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedMax(y Float64x4, z Mask64x4) Float64x4

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedMax(y Float64x8, z Mask64x8) Float64x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedMax(y Int8x16, z Mask8x16) Int8x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedMax(y Int8x32, z Mask8x32) Int8x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedMax(y Int8x64, z Mask8x64) Int8x64

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedMax(y Int16x8, z Mask16x8) Int16x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedMax(y Int16x16, z Mask16x16) Int16x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedMax(y Int16x32, z Mask16x32) Int16x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedMax(y Int32x4, z Mask32x4) Int32x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedMax(y Int32x8, z Mask32x8) Int32x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedMax(y Int32x16, z Mask32x16) Int32x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedMax(y Int64x2, z Mask64x2) Int64x2

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedMax(y Int64x4, z Mask64x4) Int64x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedMax(y Int64x8, z Mask64x8) Int64x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedMax(y Uint8x16, z Mask8x16) Uint8x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedMax(y Uint8x32, z Mask8x32) Uint8x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedMax(y Uint8x64, z Mask8x64) Uint8x64

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedMax(y Uint16x8, z Mask16x8) Uint16x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedMax(y Uint16x16, z Mask16x16) Uint16x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedMax(y Uint16x32, z Mask16x32) Uint16x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedMax(y Uint32x4, z Mask32x4) Uint32x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedMax(y Uint32x8, z Mask32x8) Uint32x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedMax(y Uint32x16, z Mask32x16) Uint32x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedMax(y Uint64x2, z Mask64x2) Uint64x2

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedMax(y Uint64x4, z Mask64x4) Uint64x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedMax(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedMin */

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedMin(y Float32x4, z Mask32x4) Float32x4

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedMin(y Float32x8, z Mask32x8) Float32x8

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedMin(y Float32x16, z Mask32x16) Float32x16

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedMin(y Float64x2, z Mask64x2) Float64x2

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedMin(y Float64x4, z Mask64x4) Float64x4

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedMin(y Float64x8, z Mask64x8) Float64x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedMin(y Int8x16, z Mask8x16) Int8x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedMin(y Int8x32, z Mask8x32) Int8x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedMin(y Int8x64, z Mask8x64) Int8x64

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedMin(y Int16x8, z Mask16x8) Int16x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedMin(y Int16x16, z Mask16x16) Int16x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedMin(y Int16x32, z Mask16x32) Int16x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedMin(y Int32x4, z Mask32x4) Int32x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedMin(y Int32x8, z Mask32x8) Int32x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedMin(y Int32x16, z Mask32x16) Int32x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedMin(y Int64x2, z Mask64x2) Int64x2

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedMin(y Int64x4, z Mask64x4) Int64x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedMin(y Int64x8, z Mask64x8) Int64x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedMin(y Uint8x16, z Mask8x16) Uint8x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedMin(y Uint8x32, z Mask8x32) Uint8x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedMin(y Uint8x64, z Mask8x64) Uint8x64

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedMin(y Uint16x8, z Mask16x8) Uint16x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedMin(y Uint16x16, z Mask16x16) Uint16x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedMin(y Uint16x32, z Mask16x32) Uint16x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedMin(y Uint32x4, z Mask32x4) Uint32x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedMin(y Uint32x8, z Mask32x8) Uint32x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedMin(y Uint32x16, z Mask32x16) Uint32x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedMin(y Uint64x2, z Mask64x2) Uint64x2

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedMin(y Uint64x4, z Mask64x4) Uint64x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedMin(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedMul */

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedMul(y Float32x4, z Mask32x4) Float32x4

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedMul(y Float32x8, z Mask32x8) Float32x8

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedMul(y Float32x16, z Mask32x16) Float32x16

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedMul(y Float64x2, z Mask64x2) Float64x2

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedMul(y Float64x4, z Mask64x4) Float64x4

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedMul(y Float64x8, z Mask64x8) Float64x8

/* MaskedMulByPowOf2 */

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedMulByPowOf2(y Float32x4, z Mask32x4) Float32x4

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedMulByPowOf2(y Float32x8, z Mask32x8) Float32x8

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedMulByPowOf2(y Float32x16, z Mask32x16) Float32x16

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedMulByPowOf2(y Float64x2, z Mask64x2) Float64x2

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedMulByPowOf2(y Float64x4, z Mask64x4) Float64x4

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedMulByPowOf2(y Float64x8, z Mask64x8) Float64x8

/* MaskedMulEvenWiden */

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedMulEvenWiden(y Int64x2, z Mask64x2) Int64x2

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedMulEvenWiden(y Int64x4, z Mask64x4) Int64x4

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedMulEvenWiden(y Int64x8, z Mask64x8) Int64x8

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedMulEvenWiden(y Uint64x2, z Mask64x2) Uint64x2

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedMulEvenWiden(y Uint64x4, z Mask64x4) Uint64x4

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedMulEvenWiden(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedMulHigh */

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedMulHigh(y Int16x8, z Mask16x8) Int16x8

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedMulHigh(y Int16x16, z Mask16x16) Int16x16

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedMulHigh(y Int16x32, z Mask16x32) Int16x32

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedMulHigh(y Uint16x8, z Mask16x8) Uint16x8

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedMulHigh(y Uint16x16, z Mask16x16) Uint16x16

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedMulHigh(y Uint16x32, z Mask16x32) Uint16x32

/* MaskedMulLow */

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedMulLow(y Int16x8, z Mask16x8) Int16x8

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedMulLow(y Int16x16, z Mask16x16) Int16x16

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedMulLow(y Int16x32, z Mask16x32) Int16x32

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedMulLow(y Int32x4, z Mask32x4) Int32x4

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedMulLow(y Int32x8, z Mask32x8) Int32x8

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedMulLow(y Int32x16, z Mask32x16) Int32x16

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedMulLow(y Int64x2, z Mask64x2) Int64x2

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedMulLow(y Int64x4, z Mask64x4) Int64x4

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedMulLow(y Int64x8, z Mask64x8) Int64x8

/* MaskedNotEqual */

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedNotEqual(y Float32x4, z Mask32x4) Mask32x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedNotEqual(y Float32x8, z Mask32x8) Mask32x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedNotEqual(y Float32x16, z Mask32x16) Mask32x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedNotEqual(y Float64x2, z Mask64x2) Mask64x2

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedNotEqual(y Float64x4, z Mask64x4) Mask64x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedNotEqual(y Float64x8, z Mask64x8) Mask64x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedNotEqual(y Int8x16, z Mask8x16) Mask8x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedNotEqual(y Int8x32, z Mask8x32) Mask8x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedNotEqual(y Int8x64, z Mask8x64) Mask8x64

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedNotEqual(y Int16x8, z Mask16x8) Mask16x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedNotEqual(y Int16x16, z Mask16x16) Mask16x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedNotEqual(y Int16x32, z Mask16x32) Mask16x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedNotEqual(y Int32x4, z Mask32x4) Mask32x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedNotEqual(y Int32x8, z Mask32x8) Mask32x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedNotEqual(y Int32x16, z Mask32x16) Mask32x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedNotEqual(y Int64x2, z Mask64x2) Mask64x2

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedNotEqual(y Int64x4, z Mask64x4) Mask64x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedNotEqual(y Int64x8, z Mask64x8) Mask64x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedNotEqual(y Uint8x16, z Mask8x16) Mask8x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedNotEqual(y Uint8x32, z Mask8x32) Mask8x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedNotEqual(y Uint8x64, z Mask8x64) Mask8x64

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedNotEqual(y Uint16x8, z Mask16x8) Mask16x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedNotEqual(y Uint16x16, z Mask16x16) Mask16x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedNotEqual(y Uint16x32, z Mask16x32) Mask16x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedNotEqual(y Uint32x4, z Mask32x4) Mask32x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedNotEqual(y Uint32x8, z Mask32x8) Mask32x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedNotEqual(y Uint32x16, z Mask32x16) Mask32x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedNotEqual(y Uint64x2, z Mask64x2) Mask64x2

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedNotEqual(y Uint64x4, z Mask64x4) Mask64x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedNotEqual(y Uint64x8, z Mask64x8) Mask64x8

/* MaskedOr */

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedOr(y Float32x4, z Mask32x4) Float32x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedOr(y Float32x8, z Mask32x8) Float32x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedOr(y Float32x16, z Mask32x16) Float32x16

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedOr(y Float64x2, z Mask64x2) Float64x2

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedOr(y Float64x4, z Mask64x4) Float64x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedOr(y Float64x8, z Mask64x8) Float64x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedOr(y Int32x4, z Mask32x4) Int32x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedOr(y Int32x8, z Mask32x8) Int32x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedOr(y Int32x16, z Mask32x16) Int32x16

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedOr(y Int64x2, z Mask64x2) Int64x2

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedOr(y Int64x4, z Mask64x4) Int64x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedOr(y Int64x8, z Mask64x8) Int64x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedOr(y Uint32x4, z Mask32x4) Uint32x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedOr(y Uint32x8, z Mask32x8) Uint32x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedOr(y Uint32x16, z Mask32x16) Uint32x16

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedOr(y Uint64x2, z Mask64x2) Uint64x2

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedOr(y Uint64x4, z Mask64x4) Uint64x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedOr(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedPairDotProd */

// PairDotProd multiplies the elements and add the pairs together,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDWD, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedPairDotProd(y Int16x8, z Mask16x8) Int32x4

// PairDotProd multiplies the elements and add the pairs together,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDWD, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedPairDotProd(y Int16x16, z Mask16x16) Int32x8

// PairDotProd multiplies the elements and add the pairs together,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDWD, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedPairDotProd(y Int16x32, z Mask16x32) Int32x16

/* MaskedPairDotProdAccumulate */

// PairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedPairDotProdAccumulate(y Int16x8, z Int16x8, u Mask32x4) Int32x4

// PairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedPairDotProdAccumulate(y Int16x16, z Int16x16, u Mask32x8) Int32x8

// PairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedPairDotProdAccumulate(y Int16x32, z Int16x32, u Mask32x16) Int32x16

/* MaskedPopCount */

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedPopCount(y Mask8x16) Int8x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedPopCount(y Mask8x32) Int8x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedPopCount(y Mask8x64) Int8x64

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedPopCount(y Mask16x8) Int16x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedPopCount(y Mask16x16) Int16x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedPopCount(y Mask16x32) Int16x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedPopCount(y Mask32x4) Int32x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedPopCount(y Mask32x8) Int32x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedPopCount(y Mask32x16) Int32x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedPopCount(y Mask64x2) Int64x2

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedPopCount(y Mask64x4) Int64x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedPopCount(y Mask64x8) Int64x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedPopCount(y Mask8x16) Uint8x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedPopCount(y Mask8x32) Uint8x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedPopCount(y Mask8x64) Uint8x64

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedPopCount(y Mask16x8) Uint16x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedPopCount(y Mask16x16) Uint16x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedPopCount(y Mask16x32) Uint16x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedPopCount(y Mask32x4) Uint32x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedPopCount(y Mask32x8) Uint32x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedPopCount(y Mask32x16) Uint32x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedPopCount(y Mask64x2) Uint64x2

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedPopCount(y Mask64x4) Uint64x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedPopCount(y Mask64x8) Uint64x8

/* MaskedRotateAllLeft */

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedRotateAllLeft(imm uint8, y Mask32x4) Int32x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedRotateAllLeft(imm uint8, y Mask32x8) Int32x8

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedRotateAllLeft(imm uint8, y Mask32x16) Int32x16

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedRotateAllLeft(imm uint8, y Mask64x2) Int64x2

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedRotateAllLeft(imm uint8, y Mask64x4) Int64x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedRotateAllLeft(imm uint8, y Mask64x8) Int64x8

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedRotateAllLeft(imm uint8, y Mask32x4) Uint32x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedRotateAllLeft(imm uint8, y Mask32x8) Uint32x8

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedRotateAllLeft(imm uint8, y Mask32x16) Uint32x16

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedRotateAllLeft(imm uint8, y Mask64x2) Uint64x2

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedRotateAllLeft(imm uint8, y Mask64x4) Uint64x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedRotateAllLeft(imm uint8, y Mask64x8) Uint64x8

/* MaskedRotateAllRight */

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedRotateAllRight(imm uint8, y Mask32x4) Int32x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedRotateAllRight(imm uint8, y Mask32x8) Int32x8

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedRotateAllRight(imm uint8, y Mask32x16) Int32x16

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedRotateAllRight(imm uint8, y Mask64x2) Int64x2

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedRotateAllRight(imm uint8, y Mask64x4) Int64x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedRotateAllRight(imm uint8, y Mask64x8) Int64x8

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedRotateAllRight(imm uint8, y Mask32x4) Uint32x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedRotateAllRight(imm uint8, y Mask32x8) Uint32x8

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedRotateAllRight(imm uint8, y Mask32x16) Uint32x16

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedRotateAllRight(imm uint8, y Mask64x2) Uint64x2

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedRotateAllRight(imm uint8, y Mask64x4) Uint64x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedRotateAllRight(imm uint8, y Mask64x8) Uint64x8

/* MaskedRotateLeft */

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedRotateLeft(y Int32x4, z Mask32x4) Int32x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedRotateLeft(y Int32x8, z Mask32x8) Int32x8

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedRotateLeft(y Int32x16, z Mask32x16) Int32x16

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedRotateLeft(y Int64x2, z Mask64x2) Int64x2

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedRotateLeft(y Int64x4, z Mask64x4) Int64x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedRotateLeft(y Int64x8, z Mask64x8) Int64x8

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedRotateLeft(y Uint32x4, z Mask32x4) Uint32x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedRotateLeft(y Uint32x8, z Mask32x8) Uint32x8

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedRotateLeft(y Uint32x16, z Mask32x16) Uint32x16

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedRotateLeft(y Uint64x2, z Mask64x2) Uint64x2

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedRotateLeft(y Uint64x4, z Mask64x4) Uint64x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedRotateLeft(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedRotateRight */

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedRotateRight(y Int32x4, z Mask32x4) Int32x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedRotateRight(y Int32x8, z Mask32x8) Int32x8

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedRotateRight(y Int32x16, z Mask32x16) Int32x16

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedRotateRight(y Int64x2, z Mask64x2) Int64x2

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedRotateRight(y Int64x4, z Mask64x4) Int64x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedRotateRight(y Int64x8, z Mask64x8) Int64x8

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedRotateRight(y Uint32x4, z Mask32x4) Uint32x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedRotateRight(y Uint32x8, z Mask32x8) Uint32x8

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedRotateRight(y Uint32x16, z Mask32x16) Uint32x16

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedRotateRight(y Uint64x2, z Mask64x2) Uint64x2

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedRotateRight(y Uint64x4, z Mask64x4) Uint64x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedRotateRight(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedRoundSuppressExceptionWithPrecision */

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedRoundSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedRoundSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedRoundSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedRoundSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedRoundSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedRoundSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedRoundWithPrecision */

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedRoundWithPrecision(imm uint8, y Mask32x4) Float32x4

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedRoundWithPrecision(imm uint8, y Mask32x8) Float32x8

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedRoundWithPrecision(imm uint8, y Mask32x16) Float32x16

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedRoundWithPrecision(imm uint8, y Mask64x2) Float64x2

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedRoundWithPrecision(imm uint8, y Mask64x4) Float64x4

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedRoundWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedSaturatedAdd */

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedSaturatedAdd(y Int8x16, z Mask8x16) Int8x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedSaturatedAdd(y Int8x32, z Mask8x32) Int8x32

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedSaturatedAdd(y Int8x64, z Mask8x64) Int8x64

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedSaturatedAdd(y Int16x8, z Mask16x8) Int16x8

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedSaturatedAdd(y Int16x16, z Mask16x16) Int16x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedSaturatedAdd(y Int16x32, z Mask16x32) Int16x32

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedSaturatedAdd(y Uint8x16, z Mask8x16) Uint8x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedSaturatedAdd(y Uint8x32, z Mask8x32) Uint8x32

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedSaturatedAdd(y Uint8x64, z Mask8x64) Uint8x64

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedSaturatedAdd(y Uint16x8, z Mask16x8) Uint16x8

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedSaturatedAdd(y Uint16x16, z Mask16x16) Uint16x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedSaturatedAdd(y Uint16x32, z Mask16x32) Uint16x32

/* MaskedSaturatedPairDotProdAccumulate */

// SaturatedPairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSDS, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedSaturatedPairDotProdAccumulate(y Int16x8, z Int16x8, u Mask32x4) Int32x4

// SaturatedPairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSDS, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedSaturatedPairDotProdAccumulate(y Int16x16, z Int16x16, u Mask32x8) Int32x8

// SaturatedPairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSDS, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedSaturatedPairDotProdAccumulate(y Int16x32, z Int16x32, u Mask32x16) Int32x16

/* MaskedSaturatedSub */

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedSaturatedSub(y Int8x16, z Mask8x16) Int8x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedSaturatedSub(y Int8x32, z Mask8x32) Int8x32

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedSaturatedSub(y Int8x64, z Mask8x64) Int8x64

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedSaturatedSub(y Int16x8, z Mask16x8) Int16x8

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedSaturatedSub(y Int16x16, z Mask16x16) Int16x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedSaturatedSub(y Int16x32, z Mask16x32) Int16x32

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedSaturatedSub(y Uint8x16, z Mask8x16) Uint8x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedSaturatedSub(y Uint8x32, z Mask8x32) Uint8x32

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedSaturatedSub(y Uint8x64, z Mask8x64) Uint8x64

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedSaturatedSub(y Uint16x8, z Mask16x8) Uint16x8

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedSaturatedSub(y Uint16x16, z Mask16x16) Uint16x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedSaturatedSub(y Uint16x32, z Mask16x32) Uint16x32

/* MaskedSaturatedUnsignedSignedPairDotProd */

// SaturatedPairDotProd multiplies the elements and add the pairs together with saturation,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDUBSW, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedSaturatedUnsignedSignedPairDotProd(y Int8x16, z Mask16x8) Int16x8

// SaturatedPairDotProd multiplies the elements and add the pairs together with saturation,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDUBSW, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedSaturatedUnsignedSignedPairDotProd(y Int8x32, z Mask16x16) Int16x16

// SaturatedPairDotProd multiplies the elements and add the pairs together with saturation,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDUBSW, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedSaturatedUnsignedSignedPairDotProd(y Int8x64, z Mask16x32) Int16x32

/* MaskedSaturatedUnsignedSignedQuadDotProdAccumulate */

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedSaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16, u Mask32x4) Int32x4

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedSaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32, u Mask32x8) Int32x8

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedSaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64, u Mask32x16) Int32x16

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedSaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16, u Mask32x4) Uint32x4

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedSaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32, u Mask32x8) Uint32x8

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedSaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64, u Mask32x16) Uint32x16

/* MaskedShiftAllLeft */

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftAllLeft(y uint64, z Mask64x2) Int64x2

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftAllLeft(y uint64, z Mask64x4) Int64x4

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftAllLeft(y uint64, z Mask64x8) Int64x8

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftAllLeft(y uint64, z Mask64x2) Uint64x2

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftAllLeft(y uint64, z Mask64x4) Uint64x4

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftAllLeft(y uint64, z Mask64x8) Uint64x8

/* MaskedShiftAllLeftAndFillUpperFrom */

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int16x8, z Mask16x8) Int16x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int16x16, z Mask16x16) Int16x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int16x32, z Mask16x32) Int16x32

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int32x4, z Mask32x4) Int32x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int32x8, z Mask32x8) Int32x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int32x16, z Mask32x16) Int32x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int64x2, z Mask64x2) Int64x2

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int64x4, z Mask64x4) Int64x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Int64x8, z Mask64x8) Int64x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint16x8, z Mask16x8) Uint16x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint16x16, z Mask16x16) Uint16x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint16x32, z Mask16x32) Uint16x32

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint32x4, z Mask32x4) Uint32x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint32x8, z Mask32x8) Uint32x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint32x16, z Mask32x16) Uint32x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint64x2, z Mask64x2) Uint64x2

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint64x4, z Mask64x4) Uint64x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftAllLeftAndFillUpperFrom(imm uint8, y Uint64x8, z Mask64x8) Uint64x8

/* MaskedShiftAllRight */

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftAllRight(y uint64, z Mask64x2) Int64x2

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftAllRight(y uint64, z Mask64x4) Int64x4

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftAllRight(y uint64, z Mask64x8) Int64x8

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftAllRight(y uint64, z Mask64x2) Uint64x2

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftAllRight(y uint64, z Mask64x4) Uint64x4

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftAllRight(y uint64, z Mask64x8) Uint64x8

/* MaskedShiftAllRightAndFillUpperFrom */

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int16x8, z Mask16x8) Int16x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int16x16, z Mask16x16) Int16x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int16x32, z Mask16x32) Int16x32

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int32x4, z Mask32x4) Int32x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int32x8, z Mask32x8) Int32x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int32x16, z Mask32x16) Int32x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int64x2, z Mask64x2) Int64x2

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int64x4, z Mask64x4) Int64x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Int64x8, z Mask64x8) Int64x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint16x8, z Mask16x8) Uint16x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint16x16, z Mask16x16) Uint16x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint16x32, z Mask16x32) Uint16x32

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint32x4, z Mask32x4) Uint32x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint32x8, z Mask32x8) Uint32x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint32x16, z Mask32x16) Uint32x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint64x2, z Mask64x2) Uint64x2

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint64x4, z Mask64x4) Uint64x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftAllRightAndFillUpperFrom(imm uint8, y Uint64x8, z Mask64x8) Uint64x8

/* MaskedShiftAllRightSignExtended */

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftAllRightSignExtended(y uint64, z Mask64x2) Int64x2

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftAllRightSignExtended(y uint64, z Mask64x4) Int64x4

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftAllRightSignExtended(y uint64, z Mask64x8) Int64x8

/* MaskedShiftLeft */

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftLeft(y Int16x8, z Mask16x8) Int16x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftLeft(y Int16x16, z Mask16x16) Int16x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftLeft(y Int16x32, z Mask16x32) Int16x32

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftLeft(y Int32x4, z Mask32x4) Int32x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftLeft(y Int32x8, z Mask32x8) Int32x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftLeft(y Int32x16, z Mask32x16) Int32x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftLeft(y Int64x2, z Mask64x2) Int64x2

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftLeft(y Int64x4, z Mask64x4) Int64x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftLeft(y Int64x8, z Mask64x8) Int64x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftLeft(y Uint16x8, z Mask16x8) Uint16x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftLeft(y Uint16x16, z Mask16x16) Uint16x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftLeft(y Uint16x32, z Mask16x32) Uint16x32

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftLeft(y Uint32x4, z Mask32x4) Uint32x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftLeft(y Uint32x8, z Mask32x8) Uint32x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftLeft(y Uint32x16, z Mask32x16) Uint32x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftLeft(y Uint64x2, z Mask64x2) Uint64x2

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftLeft(y Uint64x4, z Mask64x4) Uint64x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftLeft(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedShiftLeftAndFillUpperFrom */

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftLeftAndFillUpperFrom(y Int16x8, z Int16x8, u Mask16x8) Int16x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftLeftAndFillUpperFrom(y Int16x16, z Int16x16, u Mask16x16) Int16x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftLeftAndFillUpperFrom(y Int16x32, z Int16x32, u Mask16x32) Int16x32

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftLeftAndFillUpperFrom(y Int32x4, z Int32x4, u Mask32x4) Int32x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftLeftAndFillUpperFrom(y Int32x8, z Int32x8, u Mask32x8) Int32x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftLeftAndFillUpperFrom(y Int32x16, z Int32x16, u Mask32x16) Int32x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftLeftAndFillUpperFrom(y Int64x2, z Int64x2, u Mask64x2) Int64x2

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftLeftAndFillUpperFrom(y Int64x4, z Int64x4, u Mask64x4) Int64x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftLeftAndFillUpperFrom(y Int64x8, z Int64x8, u Mask64x8) Int64x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftLeftAndFillUpperFrom(y Uint16x8, z Uint16x8, u Mask16x8) Uint16x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftLeftAndFillUpperFrom(y Uint16x16, z Uint16x16, u Mask16x16) Uint16x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftLeftAndFillUpperFrom(y Uint16x32, z Uint16x32, u Mask16x32) Uint16x32

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftLeftAndFillUpperFrom(y Uint32x4, z Uint32x4, u Mask32x4) Uint32x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftLeftAndFillUpperFrom(y Uint32x8, z Uint32x8, u Mask32x8) Uint32x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftLeftAndFillUpperFrom(y Uint32x16, z Uint32x16, u Mask32x16) Uint32x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftLeftAndFillUpperFrom(y Uint64x2, z Uint64x2, u Mask64x2) Uint64x2

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftLeftAndFillUpperFrom(y Uint64x4, z Uint64x4, u Mask64x4) Uint64x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftLeftAndFillUpperFrom(y Uint64x8, z Uint64x8, u Mask64x8) Uint64x8

/* MaskedShiftRight */

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftRight(y Int16x8, z Mask16x8) Int16x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftRight(y Int16x16, z Mask16x16) Int16x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftRight(y Int16x32, z Mask16x32) Int16x32

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftRight(y Int32x4, z Mask32x4) Int32x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftRight(y Int32x8, z Mask32x8) Int32x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftRight(y Int32x16, z Mask32x16) Int32x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftRight(y Int64x2, z Mask64x2) Int64x2

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftRight(y Int64x4, z Mask64x4) Int64x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftRight(y Int64x8, z Mask64x8) Int64x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftRight(y Uint16x8, z Mask16x8) Uint16x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftRight(y Uint16x16, z Mask16x16) Uint16x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftRight(y Uint16x32, z Mask16x32) Uint16x32

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftRight(y Uint32x4, z Mask32x4) Uint32x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftRight(y Uint32x8, z Mask32x8) Uint32x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftRight(y Uint32x16, z Mask32x16) Uint32x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftRight(y Uint64x2, z Mask64x2) Uint64x2

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftRight(y Uint64x4, z Mask64x4) Uint64x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftRight(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedShiftRightAndFillUpperFrom */

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftRightAndFillUpperFrom(y Int16x8, z Int16x8, u Mask16x8) Int16x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftRightAndFillUpperFrom(y Int16x16, z Int16x16, u Mask16x16) Int16x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftRightAndFillUpperFrom(y Int16x32, z Int16x32, u Mask16x32) Int16x32

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftRightAndFillUpperFrom(y Int32x4, z Int32x4, u Mask32x4) Int32x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftRightAndFillUpperFrom(y Int32x8, z Int32x8, u Mask32x8) Int32x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftRightAndFillUpperFrom(y Int32x16, z Int32x16, u Mask32x16) Int32x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftRightAndFillUpperFrom(y Int64x2, z Int64x2, u Mask64x2) Int64x2

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftRightAndFillUpperFrom(y Int64x4, z Int64x4, u Mask64x4) Int64x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftRightAndFillUpperFrom(y Int64x8, z Int64x8, u Mask64x8) Int64x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftRightAndFillUpperFrom(y Uint16x8, z Uint16x8, u Mask16x8) Uint16x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftRightAndFillUpperFrom(y Uint16x16, z Uint16x16, u Mask16x16) Uint16x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftRightAndFillUpperFrom(y Uint16x32, z Uint16x32, u Mask16x32) Uint16x32

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftRightAndFillUpperFrom(y Uint32x4, z Uint32x4, u Mask32x4) Uint32x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftRightAndFillUpperFrom(y Uint32x8, z Uint32x8, u Mask32x8) Uint32x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftRightAndFillUpperFrom(y Uint32x16, z Uint32x16, u Mask32x16) Uint32x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftRightAndFillUpperFrom(y Uint64x2, z Uint64x2, u Mask64x2) Uint64x2

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftRightAndFillUpperFrom(y Uint64x4, z Uint64x4, u Mask64x4) Uint64x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftRightAndFillUpperFrom(y Uint64x8, z Uint64x8, u Mask64x8) Uint64x8

/* MaskedShiftRightSignExtended */

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedShiftRightSignExtended(y Int16x8, z Mask16x8) Int16x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedShiftRightSignExtended(y Int16x16, z Mask16x16) Int16x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedShiftRightSignExtended(y Int16x32, z Mask16x32) Int16x32

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedShiftRightSignExtended(y Int32x4, z Mask32x4) Int32x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedShiftRightSignExtended(y Int32x8, z Mask32x8) Int32x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedShiftRightSignExtended(y Int32x16, z Mask32x16) Int32x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedShiftRightSignExtended(y Int64x2, z Mask64x2) Int64x2

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedShiftRightSignExtended(y Int64x4, z Mask64x4) Int64x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedShiftRightSignExtended(y Int64x8, z Mask64x8) Int64x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedShiftRightSignExtended(y Uint16x8, z Mask16x8) Uint16x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedShiftRightSignExtended(y Uint16x16, z Mask16x16) Uint16x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedShiftRightSignExtended(y Uint16x32, z Mask16x32) Uint16x32

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedShiftRightSignExtended(y Uint32x4, z Mask32x4) Uint32x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedShiftRightSignExtended(y Uint32x8, z Mask32x8) Uint32x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedShiftRightSignExtended(y Uint32x16, z Mask32x16) Uint32x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedShiftRightSignExtended(y Uint64x2, z Mask64x2) Uint64x2

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedShiftRightSignExtended(y Uint64x4, z Mask64x4) Uint64x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedShiftRightSignExtended(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedSqrt */

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedSqrt(y Mask32x4) Float32x4

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedSqrt(y Mask32x8) Float32x8

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedSqrt(y Mask32x16) Float32x16

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedSqrt(y Mask64x2) Float64x2

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedSqrt(y Mask64x4) Float64x4

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedSqrt(y Mask64x8) Float64x8

/* MaskedSub */

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedSub(y Float32x4, z Mask32x4) Float32x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedSub(y Float32x8, z Mask32x8) Float32x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedSub(y Float32x16, z Mask32x16) Float32x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedSub(y Float64x2, z Mask64x2) Float64x2

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedSub(y Float64x4, z Mask64x4) Float64x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedSub(y Float64x8, z Mask64x8) Float64x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Int8x16) MaskedSub(y Int8x16, z Mask8x16) Int8x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Int8x32) MaskedSub(y Int8x32, z Mask8x32) Int8x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Int8x64) MaskedSub(y Int8x64, z Mask8x64) Int8x64

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Int16x8) MaskedSub(y Int16x8, z Mask16x8) Int16x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Int16x16) MaskedSub(y Int16x16, z Mask16x16) Int16x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Int16x32) MaskedSub(y Int16x32, z Mask16x32) Int16x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedSub(y Int32x4, z Mask32x4) Int32x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedSub(y Int32x8, z Mask32x8) Int32x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedSub(y Int32x16, z Mask32x16) Int32x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedSub(y Int64x2, z Mask64x2) Int64x2

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedSub(y Int64x4, z Mask64x4) Int64x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedSub(y Int64x8, z Mask64x8) Int64x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Uint8x16) MaskedSub(y Uint8x16, z Mask8x16) Uint8x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Uint8x32) MaskedSub(y Uint8x32, z Mask8x32) Uint8x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Uint8x64) MaskedSub(y Uint8x64, z Mask8x64) Uint8x64

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Uint16x8) MaskedSub(y Uint16x8, z Mask16x8) Uint16x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Uint16x16) MaskedSub(y Uint16x16, z Mask16x16) Uint16x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Uint16x32) MaskedSub(y Uint16x32, z Mask16x32) Uint16x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedSub(y Uint32x4, z Mask32x4) Uint32x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedSub(y Uint32x8, z Mask32x8) Uint32x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedSub(y Uint32x16, z Mask32x16) Uint32x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedSub(y Uint64x2, z Mask64x2) Uint64x2

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedSub(y Uint64x4, z Mask64x4) Uint64x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedSub(y Uint64x8, z Mask64x8) Uint64x8

/* MaskedTruncSuppressExceptionWithPrecision */

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedTruncSuppressExceptionWithPrecision(imm uint8, y Mask32x4) Float32x4

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedTruncSuppressExceptionWithPrecision(imm uint8, y Mask32x8) Float32x8

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedTruncSuppressExceptionWithPrecision(imm uint8, y Mask32x16) Float32x16

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedTruncSuppressExceptionWithPrecision(imm uint8, y Mask64x2) Float64x2

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedTruncSuppressExceptionWithPrecision(imm uint8, y Mask64x4) Float64x4

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedTruncSuppressExceptionWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedTruncWithPrecision */

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedTruncWithPrecision(imm uint8, y Mask32x4) Float32x4

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedTruncWithPrecision(imm uint8, y Mask32x8) Float32x8

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedTruncWithPrecision(imm uint8, y Mask32x16) Float32x16

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedTruncWithPrecision(imm uint8, y Mask64x2) Float64x2

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedTruncWithPrecision(imm uint8, y Mask64x4) Float64x4

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedTruncWithPrecision(imm uint8, y Mask64x8) Float64x8

/* MaskedUnsignedSignedQuadDotProdAccumulate */

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedUnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16, u Mask32x4) Int32x4

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedUnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32, u Mask32x8) Int32x8

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedUnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64, u Mask32x16) Int32x16

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedUnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16, u Mask32x4) Uint32x4

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedUnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32, u Mask32x8) Uint32x8

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedUnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64, u Mask32x16) Uint32x16

/* MaskedXor */

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPS, CPU Feature: AVX512EVEX
func (x Float32x4) MaskedXor(y Float32x4, z Mask32x4) Float32x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPS, CPU Feature: AVX512EVEX
func (x Float32x8) MaskedXor(y Float32x8, z Mask32x8) Float32x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPS, CPU Feature: AVX512EVEX
func (x Float32x16) MaskedXor(y Float32x16, z Mask32x16) Float32x16

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPD, CPU Feature: AVX512EVEX
func (x Float64x2) MaskedXor(y Float64x2, z Mask64x2) Float64x2

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPD, CPU Feature: AVX512EVEX
func (x Float64x4) MaskedXor(y Float64x4, z Mask64x4) Float64x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPD, CPU Feature: AVX512EVEX
func (x Float64x8) MaskedXor(y Float64x8, z Mask64x8) Float64x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Int32x4) MaskedXor(y Int32x4, z Mask32x4) Int32x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Int32x8) MaskedXor(y Int32x8, z Mask32x8) Int32x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Int32x16) MaskedXor(y Int32x16, z Mask32x16) Int32x16

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Int64x2) MaskedXor(y Int64x2, z Mask64x2) Int64x2

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Int64x4) MaskedXor(y Int64x4, z Mask64x4) Int64x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Int64x8) MaskedXor(y Int64x8, z Mask64x8) Int64x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Uint32x4) MaskedXor(y Uint32x4, z Mask32x4) Uint32x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Uint32x8) MaskedXor(y Uint32x8, z Mask32x8) Uint32x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Uint32x16) MaskedXor(y Uint32x16, z Mask32x16) Uint32x16

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MaskedXor(y Uint64x2, z Mask64x2) Uint64x2

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MaskedXor(y Uint64x4, z Mask64x4) Uint64x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MaskedXor(y Uint64x8, z Mask64x8) Uint64x8

/* Max */

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPS, CPU Feature: AVX
func (x Float32x4) Max(y Float32x4) Float32x4

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPS, CPU Feature: AVX
func (x Float32x8) Max(y Float32x8) Float32x8

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPS, CPU Feature: AVX512EVEX
func (x Float32x16) Max(y Float32x16) Float32x16

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPD, CPU Feature: AVX
func (x Float64x2) Max(y Float64x2) Float64x2

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPD, CPU Feature: AVX
func (x Float64x4) Max(y Float64x4) Float64x4

// Max computes the maximum of corresponding elements.
//
// Asm: VMAXPD, CPU Feature: AVX512EVEX
func (x Float64x8) Max(y Float64x8) Float64x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSB, CPU Feature: AVX
func (x Int8x16) Max(y Int8x16) Int8x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSB, CPU Feature: AVX2
func (x Int8x32) Max(y Int8x32) Int8x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSB, CPU Feature: AVX512EVEX
func (x Int8x64) Max(y Int8x64) Int8x64

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSW, CPU Feature: AVX
func (x Int16x8) Max(y Int16x8) Int16x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSW, CPU Feature: AVX2
func (x Int16x16) Max(y Int16x16) Int16x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSW, CPU Feature: AVX512EVEX
func (x Int16x32) Max(y Int16x32) Int16x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSD, CPU Feature: AVX
func (x Int32x4) Max(y Int32x4) Int32x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSD, CPU Feature: AVX2
func (x Int32x8) Max(y Int32x8) Int32x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSD, CPU Feature: AVX512EVEX
func (x Int32x16) Max(y Int32x16) Int32x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSQ, CPU Feature: AVX512EVEX
func (x Int64x2) Max(y Int64x2) Int64x2

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSQ, CPU Feature: AVX512EVEX
func (x Int64x4) Max(y Int64x4) Int64x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXSQ, CPU Feature: AVX512EVEX
func (x Int64x8) Max(y Int64x8) Int64x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUB, CPU Feature: AVX
func (x Uint8x16) Max(y Uint8x16) Uint8x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUB, CPU Feature: AVX2
func (x Uint8x32) Max(y Uint8x32) Uint8x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUB, CPU Feature: AVX512EVEX
func (x Uint8x64) Max(y Uint8x64) Uint8x64

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUW, CPU Feature: AVX
func (x Uint16x8) Max(y Uint16x8) Uint16x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUW, CPU Feature: AVX2
func (x Uint16x16) Max(y Uint16x16) Uint16x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUW, CPU Feature: AVX512EVEX
func (x Uint16x32) Max(y Uint16x32) Uint16x32

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUD, CPU Feature: AVX
func (x Uint32x4) Max(y Uint32x4) Uint32x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUD, CPU Feature: AVX2
func (x Uint32x8) Max(y Uint32x8) Uint32x8

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUD, CPU Feature: AVX512EVEX
func (x Uint32x16) Max(y Uint32x16) Uint32x16

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) Max(y Uint64x2) Uint64x2

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) Max(y Uint64x4) Uint64x4

// Max computes the maximum of corresponding elements.
//
// Asm: VPMAXUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Max(y Uint64x8) Uint64x8

/* Min */

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPS, CPU Feature: AVX
func (x Float32x4) Min(y Float32x4) Float32x4

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPS, CPU Feature: AVX
func (x Float32x8) Min(y Float32x8) Float32x8

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPS, CPU Feature: AVX512EVEX
func (x Float32x16) Min(y Float32x16) Float32x16

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPD, CPU Feature: AVX
func (x Float64x2) Min(y Float64x2) Float64x2

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPD, CPU Feature: AVX
func (x Float64x4) Min(y Float64x4) Float64x4

// Min computes the minimum of corresponding elements.
//
// Asm: VMINPD, CPU Feature: AVX512EVEX
func (x Float64x8) Min(y Float64x8) Float64x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSB, CPU Feature: AVX
func (x Int8x16) Min(y Int8x16) Int8x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSB, CPU Feature: AVX2
func (x Int8x32) Min(y Int8x32) Int8x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSB, CPU Feature: AVX512EVEX
func (x Int8x64) Min(y Int8x64) Int8x64

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSW, CPU Feature: AVX
func (x Int16x8) Min(y Int16x8) Int16x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSW, CPU Feature: AVX2
func (x Int16x16) Min(y Int16x16) Int16x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSW, CPU Feature: AVX512EVEX
func (x Int16x32) Min(y Int16x32) Int16x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSD, CPU Feature: AVX
func (x Int32x4) Min(y Int32x4) Int32x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSD, CPU Feature: AVX2
func (x Int32x8) Min(y Int32x8) Int32x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSD, CPU Feature: AVX512EVEX
func (x Int32x16) Min(y Int32x16) Int32x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSQ, CPU Feature: AVX512EVEX
func (x Int64x2) Min(y Int64x2) Int64x2

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSQ, CPU Feature: AVX512EVEX
func (x Int64x4) Min(y Int64x4) Int64x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINSQ, CPU Feature: AVX512EVEX
func (x Int64x8) Min(y Int64x8) Int64x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUB, CPU Feature: AVX
func (x Uint8x16) Min(y Uint8x16) Uint8x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUB, CPU Feature: AVX2
func (x Uint8x32) Min(y Uint8x32) Uint8x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUB, CPU Feature: AVX512EVEX
func (x Uint8x64) Min(y Uint8x64) Uint8x64

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUW, CPU Feature: AVX
func (x Uint16x8) Min(y Uint16x8) Uint16x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUW, CPU Feature: AVX2
func (x Uint16x16) Min(y Uint16x16) Uint16x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUW, CPU Feature: AVX512EVEX
func (x Uint16x32) Min(y Uint16x32) Uint16x32

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUD, CPU Feature: AVX
func (x Uint32x4) Min(y Uint32x4) Uint32x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUD, CPU Feature: AVX2
func (x Uint32x8) Min(y Uint32x8) Uint32x8

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUD, CPU Feature: AVX512EVEX
func (x Uint32x16) Min(y Uint32x16) Uint32x16

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) Min(y Uint64x2) Uint64x2

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) Min(y Uint64x4) Uint64x4

// Min computes the minimum of corresponding elements.
//
// Asm: VPMINUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Min(y Uint64x8) Uint64x8

/* Mul */

// Mul multiplies corresponding elements of two vectors.
//
// Asm: VMULPS, CPU Feature: AVX
func (x Float32x4) Mul(y Float32x4) Float32x4

// Mul multiplies corresponding elements of two vectors.
//
// Asm: VMULPS, CPU Feature: AVX
func (x Float32x8) Mul(y Float32x8) Float32x8

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPS, CPU Feature: AVX512EVEX
func (x Float32x16) Mul(y Float32x16) Float32x16

// Mul multiplies corresponding elements of two vectors.
//
// Asm: VMULPD, CPU Feature: AVX
func (x Float64x2) Mul(y Float64x2) Float64x2

// Mul multiplies corresponding elements of two vectors.
//
// Asm: VMULPD, CPU Feature: AVX
func (x Float64x4) Mul(y Float64x4) Float64x4

// Mul multiplies corresponding elements of two vectors, masked.
//
// Asm: VMULPD, CPU Feature: AVX512EVEX
func (x Float64x8) Mul(y Float64x8) Float64x8

/* MulByPowOf2 */

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPS, CPU Feature: AVX512EVEX
func (x Float32x4) MulByPowOf2(y Float32x4) Float32x4

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPS, CPU Feature: AVX512EVEX
func (x Float32x8) MulByPowOf2(y Float32x8) Float32x8

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPS, CPU Feature: AVX512EVEX
func (x Float32x16) MulByPowOf2(y Float32x16) Float32x16

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPD, CPU Feature: AVX512EVEX
func (x Float64x2) MulByPowOf2(y Float64x2) Float64x2

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPD, CPU Feature: AVX512EVEX
func (x Float64x4) MulByPowOf2(y Float64x4) Float64x4

// MulByPowOf2 multiplies elements by a power of 2.
//
// Asm: VSCALEFPD, CPU Feature: AVX512EVEX
func (x Float64x8) MulByPowOf2(y Float64x8) Float64x8

/* MulEvenWiden */

// MulEvenWiden multiplies even-indexed elements, widening the result.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX
func (x Int32x4) MulEvenWiden(y Int32x4) Int64x2

// MulEvenWiden multiplies even-indexed elements, widening the result.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX2
func (x Int32x8) MulEvenWiden(y Int32x8) Int64x4

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX512EVEX
func (x Int64x2) MulEvenWiden(y Int64x2) Int64x2

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX512EVEX
func (x Int64x4) MulEvenWiden(y Int64x4) Int64x4

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULDQ, CPU Feature: AVX512EVEX
func (x Int64x8) MulEvenWiden(y Int64x8) Int64x8

// MulEvenWiden multiplies even-indexed elements, widening the result.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX
func (x Uint32x4) MulEvenWiden(y Uint32x4) Uint64x2

// MulEvenWiden multiplies even-indexed elements, widening the result.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX2
func (x Uint32x8) MulEvenWiden(y Uint32x8) Uint64x4

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) MulEvenWiden(y Uint64x2) Uint64x2

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) MulEvenWiden(y Uint64x4) Uint64x4

// MulEvenWiden multiplies even-indexed elements, widening the result, masked.
// Result[i] = v1.Even[i] * v2.Even[i].
//
// Asm: VPMULUDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) MulEvenWiden(y Uint64x8) Uint64x8

/* MulHigh */

// MulHigh multiplies elements and stores the high part of the result.
//
// Asm: VPMULHW, CPU Feature: AVX
func (x Int16x8) MulHigh(y Int16x8) Int16x8

// MulHigh multiplies elements and stores the high part of the result.
//
// Asm: VPMULHW, CPU Feature: AVX2
func (x Int16x16) MulHigh(y Int16x16) Int16x16

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHW, CPU Feature: AVX512EVEX
func (x Int16x32) MulHigh(y Int16x32) Int16x32

// MulHigh multiplies elements and stores the high part of the result.
//
// Asm: VPMULHUW, CPU Feature: AVX
func (x Uint16x8) MulHigh(y Uint16x8) Uint16x8

// MulHigh multiplies elements and stores the high part of the result.
//
// Asm: VPMULHUW, CPU Feature: AVX2
func (x Uint16x16) MulHigh(y Uint16x16) Uint16x16

// MulHigh multiplies elements and stores the high part of the result, masked.
//
// Asm: VPMULHUW, CPU Feature: AVX512EVEX
func (x Uint16x32) MulHigh(y Uint16x32) Uint16x32

/* MulLow */

// MulLow multiplies elements and stores the low part of the result.
//
// Asm: VPMULLW, CPU Feature: AVX
func (x Int16x8) MulLow(y Int16x8) Int16x8

// MulLow multiplies elements and stores the low part of the result.
//
// Asm: VPMULLW, CPU Feature: AVX2
func (x Int16x16) MulLow(y Int16x16) Int16x16

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLW, CPU Feature: AVX512EVEX
func (x Int16x32) MulLow(y Int16x32) Int16x32

// MulLow multiplies elements and stores the low part of the result.
//
// Asm: VPMULLD, CPU Feature: AVX
func (x Int32x4) MulLow(y Int32x4) Int32x4

// MulLow multiplies elements and stores the low part of the result.
//
// Asm: VPMULLD, CPU Feature: AVX2
func (x Int32x8) MulLow(y Int32x8) Int32x8

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLD, CPU Feature: AVX512EVEX
func (x Int32x16) MulLow(y Int32x16) Int32x16

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLQ, CPU Feature: AVX512EVEX
func (x Int64x2) MulLow(y Int64x2) Int64x2

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLQ, CPU Feature: AVX512EVEX
func (x Int64x4) MulLow(y Int64x4) Int64x4

// MulLow multiplies elements and stores the low part of the result, masked.
//
// Asm: VPMULLQ, CPU Feature: AVX512EVEX
func (x Int64x8) MulLow(y Int64x8) Int64x8

/* NotEqual */

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x4) NotEqual(y Float32x4) Mask32x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPS, CPU Feature: AVX
func (x Float32x8) NotEqual(y Float32x8) Mask32x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPS, CPU Feature: AVX512EVEX
func (x Float32x16) NotEqual(y Float32x16) Mask32x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x2) NotEqual(y Float64x2) Mask64x2

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPD, CPU Feature: AVX
func (x Float64x4) NotEqual(y Float64x4) Mask64x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VCMPPD, CPU Feature: AVX512EVEX
func (x Float64x8) NotEqual(y Float64x8) Mask64x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x16) NotEqual(y Int8x16) Mask8x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x32) NotEqual(y Int8x32) Mask8x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPB, CPU Feature: AVX512EVEX
func (x Int8x64) NotEqual(y Int8x64) Mask8x64

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x8) NotEqual(y Int16x8) Mask16x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x16) NotEqual(y Int16x16) Mask16x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPW, CPU Feature: AVX512EVEX
func (x Int16x32) NotEqual(y Int16x32) Mask16x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x4) NotEqual(y Int32x4) Mask32x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x8) NotEqual(y Int32x8) Mask32x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPD, CPU Feature: AVX512EVEX
func (x Int32x16) NotEqual(y Int32x16) Mask32x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x2) NotEqual(y Int64x2) Mask64x2

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x4) NotEqual(y Int64x4) Mask64x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPQ, CPU Feature: AVX512EVEX
func (x Int64x8) NotEqual(y Int64x8) Mask64x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x16) NotEqual(y Uint8x16) Mask8x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x32) NotEqual(y Uint8x32) Mask8x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUB, CPU Feature: AVX512EVEX
func (x Uint8x64) NotEqual(y Uint8x64) Mask8x64

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x8) NotEqual(y Uint16x8) Mask16x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x16) NotEqual(y Uint16x16) Mask16x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUW, CPU Feature: AVX512EVEX
func (x Uint16x32) NotEqual(y Uint16x32) Mask16x32

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x4) NotEqual(y Uint32x4) Mask32x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x8) NotEqual(y Uint32x8) Mask32x8

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUD, CPU Feature: AVX512EVEX
func (x Uint32x16) NotEqual(y Uint32x16) Mask32x16

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x2) NotEqual(y Uint64x2) Mask64x2

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x4) NotEqual(y Uint64x4) Mask64x4

// NotEqual compares for inequality.
// Const Immediate = 4.
//
// Asm: VPCMPUQ, CPU Feature: AVX512EVEX
func (x Uint64x8) NotEqual(y Uint64x8) Mask64x8

/* Or */

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VORPS, CPU Feature: AVX
func (x Float32x4) Or(y Float32x4) Float32x4

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VORPS, CPU Feature: AVX
func (x Float32x8) Or(y Float32x8) Float32x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPS, CPU Feature: AVX512EVEX
func (x Float32x16) Or(y Float32x16) Float32x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VORPD, CPU Feature: AVX
func (x Float64x2) Or(y Float64x2) Float64x2

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VORPD, CPU Feature: AVX
func (x Float64x4) Or(y Float64x4) Float64x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VORPD, CPU Feature: AVX512EVEX
func (x Float64x8) Or(y Float64x8) Float64x8

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Int8x16) Or(y Int8x16) Int8x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Int8x32) Or(y Int8x32) Int8x32

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Int16x8) Or(y Int16x8) Int16x8

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Int16x16) Or(y Int16x16) Int16x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Int32x4) Or(y Int32x4) Int32x4

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Int32x8) Or(y Int32x8) Int32x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Int32x16) Or(y Int32x16) Int32x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Int64x2) Or(y Int64x2) Int64x2

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Int64x4) Or(y Int64x4) Int64x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Int64x8) Or(y Int64x8) Int64x8

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Uint8x16) Or(y Uint8x16) Uint8x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Uint8x32) Or(y Uint8x32) Uint8x32

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Uint16x8) Or(y Uint16x8) Uint16x8

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Uint16x16) Or(y Uint16x16) Uint16x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Uint32x4) Or(y Uint32x4) Uint32x4

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Uint32x8) Or(y Uint32x8) Uint32x8

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORD, CPU Feature: AVX512EVEX
func (x Uint32x16) Or(y Uint32x16) Uint32x16

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX
func (x Uint64x2) Or(y Uint64x2) Uint64x2

// Or performs a bitwise OR operation between two vectors.
//
// Asm: VPOR, CPU Feature: AVX2
func (x Uint64x4) Or(y Uint64x4) Uint64x4

// Or performs a masked bitwise OR operation between two vectors.
//
// Asm: VPORQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Or(y Uint64x8) Uint64x8

/* PairDotProd */

// PairDotProd multiplies the elements and add the pairs together,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDWD, CPU Feature: AVX
func (x Int16x8) PairDotProd(y Int16x8) Int32x4

// PairDotProd multiplies the elements and add the pairs together,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDWD, CPU Feature: AVX2
func (x Int16x16) PairDotProd(y Int16x16) Int32x8

// PairDotProd multiplies the elements and add the pairs together,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDWD, CPU Feature: AVX512EVEX
func (x Int16x32) PairDotProd(y Int16x32) Int32x16

/* PairDotProdAccumulate */

// PairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSD, CPU Feature: AVX_VNNI
func (x Int32x4) PairDotProdAccumulate(y Int16x8, z Int16x8) Int32x4

// PairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSD, CPU Feature: AVX_VNNI
func (x Int32x8) PairDotProdAccumulate(y Int16x16, z Int16x16) Int32x8

// PairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSD, CPU Feature: AVX512EVEX
func (x Int32x16) PairDotProdAccumulate(y Int16x32, z Int16x32) Int32x16

/* PairwiseAdd */

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VHADDPS, CPU Feature: AVX
func (x Float32x4) PairwiseAdd(y Float32x4) Float32x4

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VHADDPS, CPU Feature: AVX
func (x Float32x8) PairwiseAdd(y Float32x8) Float32x8

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VHADDPD, CPU Feature: AVX
func (x Float64x2) PairwiseAdd(y Float64x2) Float64x2

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VHADDPD, CPU Feature: AVX
func (x Float64x4) PairwiseAdd(y Float64x4) Float64x4

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDW, CPU Feature: AVX
func (x Int16x8) PairwiseAdd(y Int16x8) Int16x8

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDW, CPU Feature: AVX2
func (x Int16x16) PairwiseAdd(y Int16x16) Int16x16

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDD, CPU Feature: AVX
func (x Int32x4) PairwiseAdd(y Int32x4) Int32x4

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDD, CPU Feature: AVX2
func (x Int32x8) PairwiseAdd(y Int32x8) Int32x8

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDW, CPU Feature: AVX
func (x Uint16x8) PairwiseAdd(y Uint16x8) Uint16x8

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDW, CPU Feature: AVX2
func (x Uint16x16) PairwiseAdd(y Uint16x16) Uint16x16

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDD, CPU Feature: AVX
func (x Uint32x4) PairwiseAdd(y Uint32x4) Uint32x4

// PairwiseAdd horizontally adds adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDD, CPU Feature: AVX2
func (x Uint32x8) PairwiseAdd(y Uint32x8) Uint32x8

/* PairwiseSub */

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VHSUBPS, CPU Feature: AVX
func (x Float32x4) PairwiseSub(y Float32x4) Float32x4

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VHSUBPS, CPU Feature: AVX
func (x Float32x8) PairwiseSub(y Float32x8) Float32x8

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VHSUBPD, CPU Feature: AVX
func (x Float64x2) PairwiseSub(y Float64x2) Float64x2

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VHSUBPD, CPU Feature: AVX
func (x Float64x4) PairwiseSub(y Float64x4) Float64x4

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBW, CPU Feature: AVX
func (x Int16x8) PairwiseSub(y Int16x8) Int16x8

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBW, CPU Feature: AVX2
func (x Int16x16) PairwiseSub(y Int16x16) Int16x16

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBD, CPU Feature: AVX
func (x Int32x4) PairwiseSub(y Int32x4) Int32x4

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBD, CPU Feature: AVX2
func (x Int32x8) PairwiseSub(y Int32x8) Int32x8

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBW, CPU Feature: AVX
func (x Uint16x8) PairwiseSub(y Uint16x8) Uint16x8

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBW, CPU Feature: AVX2
func (x Uint16x16) PairwiseSub(y Uint16x16) Uint16x16

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBD, CPU Feature: AVX
func (x Uint32x4) PairwiseSub(y Uint32x4) Uint32x4

// PairwiseSub horizontally subtracts adjacent pairs of elements.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBD, CPU Feature: AVX2
func (x Uint32x8) PairwiseSub(y Uint32x8) Uint32x8

/* PopCount */

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Int8x16) PopCount() Int8x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Int8x32) PopCount() Int8x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Int8x64) PopCount() Int8x64

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Int16x8) PopCount() Int16x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Int16x16) PopCount() Int16x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Int16x32) PopCount() Int16x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Int32x4) PopCount() Int32x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Int32x8) PopCount() Int32x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Int32x16) PopCount() Int32x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Int64x2) PopCount() Int64x2

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Int64x4) PopCount() Int64x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Int64x8) PopCount() Int64x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Uint8x16) PopCount() Uint8x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Uint8x32) PopCount() Uint8x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTB, CPU Feature: AVX512EVEX
func (x Uint8x64) PopCount() Uint8x64

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Uint16x8) PopCount() Uint16x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Uint16x16) PopCount() Uint16x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTW, CPU Feature: AVX512EVEX
func (x Uint16x32) PopCount() Uint16x32

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Uint32x4) PopCount() Uint32x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Uint32x8) PopCount() Uint32x8

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTD, CPU Feature: AVX512EVEX
func (x Uint32x16) PopCount() Uint32x16

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Uint64x2) PopCount() Uint64x2

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Uint64x4) PopCount() Uint64x4

// PopCount counts the number of set bits in each element.
//
// Asm: VPOPCNTQ, CPU Feature: AVX512EVEX
func (x Uint64x8) PopCount() Uint64x8

/* RotateAllLeft */

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Int32x4) RotateAllLeft(imm8 uint8) Int32x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Int32x8) RotateAllLeft(imm8 uint8) Int32x8

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Int32x16) RotateAllLeft(imm8 uint8) Int32x16

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Int64x2) RotateAllLeft(imm8 uint8) Int64x2

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Int64x4) RotateAllLeft(imm8 uint8) Int64x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Int64x8) RotateAllLeft(imm8 uint8) Int64x8

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Uint32x4) RotateAllLeft(imm8 uint8) Uint32x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Uint32x8) RotateAllLeft(imm8 uint8) Uint32x8

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLD, CPU Feature: AVX512EVEX
func (x Uint32x16) RotateAllLeft(imm8 uint8) Uint32x16

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Uint64x2) RotateAllLeft(imm8 uint8) Uint64x2

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Uint64x4) RotateAllLeft(imm8 uint8) Uint64x4

// RotateAllLeft rotates each element to the left by the number of bits specified by the immediate.
//
// Asm: VPROLQ, CPU Feature: AVX512EVEX
func (x Uint64x8) RotateAllLeft(imm8 uint8) Uint64x8

/* RotateAllRight */

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Int32x4) RotateAllRight(imm8 uint8) Int32x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Int32x8) RotateAllRight(imm8 uint8) Int32x8

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Int32x16) RotateAllRight(imm8 uint8) Int32x16

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Int64x2) RotateAllRight(imm8 uint8) Int64x2

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Int64x4) RotateAllRight(imm8 uint8) Int64x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Int64x8) RotateAllRight(imm8 uint8) Int64x8

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Uint32x4) RotateAllRight(imm8 uint8) Uint32x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Uint32x8) RotateAllRight(imm8 uint8) Uint32x8

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORD, CPU Feature: AVX512EVEX
func (x Uint32x16) RotateAllRight(imm8 uint8) Uint32x16

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Uint64x2) RotateAllRight(imm8 uint8) Uint64x2

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Uint64x4) RotateAllRight(imm8 uint8) Uint64x4

// RotateAllRight rotates each element to the right by the number of bits specified by the immediate.
//
// Asm: VPRORQ, CPU Feature: AVX512EVEX
func (x Uint64x8) RotateAllRight(imm8 uint8) Uint64x8

/* RotateLeft */

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Int32x4) RotateLeft(y Int32x4) Int32x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Int32x8) RotateLeft(y Int32x8) Int32x8

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Int32x16) RotateLeft(y Int32x16) Int32x16

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Int64x2) RotateLeft(y Int64x2) Int64x2

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Int64x4) RotateLeft(y Int64x4) Int64x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Int64x8) RotateLeft(y Int64x8) Int64x8

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Uint32x4) RotateLeft(y Uint32x4) Uint32x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Uint32x8) RotateLeft(y Uint32x8) Uint32x8

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVD, CPU Feature: AVX512EVEX
func (x Uint32x16) RotateLeft(y Uint32x16) Uint32x16

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) RotateLeft(y Uint64x2) Uint64x2

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) RotateLeft(y Uint64x4) Uint64x4

// RotateLeft rotates each element in x to the left by the number of bits specified by y's corresponding elements.
//
// Asm: VPROLVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) RotateLeft(y Uint64x8) Uint64x8

/* RotateRight */

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Int32x4) RotateRight(y Int32x4) Int32x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Int32x8) RotateRight(y Int32x8) Int32x8

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Int32x16) RotateRight(y Int32x16) Int32x16

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Int64x2) RotateRight(y Int64x2) Int64x2

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Int64x4) RotateRight(y Int64x4) Int64x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Int64x8) RotateRight(y Int64x8) Int64x8

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Uint32x4) RotateRight(y Uint32x4) Uint32x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Uint32x8) RotateRight(y Uint32x8) Uint32x8

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVD, CPU Feature: AVX512EVEX
func (x Uint32x16) RotateRight(y Uint32x16) Uint32x16

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) RotateRight(y Uint64x2) Uint64x2

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) RotateRight(y Uint64x4) Uint64x4

// RotateRight rotates each element in x to the right by the number of bits specified by y's corresponding elements.
//
// Asm: VPRORVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) RotateRight(y Uint64x8) Uint64x8

/* Round */

// Round rounds elements to the nearest integer.
// Const Immediate = 0.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x4) Round() Float32x4

// Round rounds elements to the nearest integer.
// Const Immediate = 0.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x8) Round() Float32x8

// Round rounds elements to the nearest integer.
// Const Immediate = 0.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x2) Round() Float64x2

// Round rounds elements to the nearest integer.
// Const Immediate = 0.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x4) Round() Float64x4

/* RoundSuppressExceptionWithPrecision */

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) RoundSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) RoundSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) RoundSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) RoundSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) RoundSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// RoundSuppressExceptionWithPrecision rounds elements with specified precision, suppressing exceptions.
// Const Immediate = 8.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) RoundSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* RoundWithPrecision */

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) RoundWithPrecision(imm8 uint8) Float32x4

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) RoundWithPrecision(imm8 uint8) Float32x8

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) RoundWithPrecision(imm8 uint8) Float32x16

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) RoundWithPrecision(imm8 uint8) Float64x2

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) RoundWithPrecision(imm8 uint8) Float64x4

// RoundWithPrecision rounds elements with specified precision.
// Const Immediate = 0.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) RoundWithPrecision(imm8 uint8) Float64x8

/* SaturatedAdd */

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX
func (x Int8x16) SaturatedAdd(y Int8x16) Int8x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX2
func (x Int8x32) SaturatedAdd(y Int8x32) Int8x32

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Int8x64) SaturatedAdd(y Int8x64) Int8x64

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX
func (x Int16x8) SaturatedAdd(y Int16x8) Int16x8

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX2
func (x Int16x16) SaturatedAdd(y Int16x16) Int16x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Int16x32) SaturatedAdd(y Int16x32) Int16x32

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX
func (x Uint8x16) SaturatedAdd(y Uint8x16) Uint8x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX2
func (x Uint8x32) SaturatedAdd(y Uint8x32) Uint8x32

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSB, CPU Feature: AVX512EVEX
func (x Uint8x64) SaturatedAdd(y Uint8x64) Uint8x64

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX
func (x Uint16x8) SaturatedAdd(y Uint16x8) Uint16x8

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX2
func (x Uint16x16) SaturatedAdd(y Uint16x16) Uint16x16

// SaturatedAdd adds corresponding elements of two vectors with saturation.
//
// Asm: VPADDSW, CPU Feature: AVX512EVEX
func (x Uint16x32) SaturatedAdd(y Uint16x32) Uint16x32

/* SaturatedPairDotProdAccumulate */

// SaturatedPairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSDS, CPU Feature: AVX_VNNI
func (x Int32x4) SaturatedPairDotProdAccumulate(y Int16x8, z Int16x8) Int32x4

// SaturatedPairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSDS, CPU Feature: AVX_VNNI
func (x Int32x8) SaturatedPairDotProdAccumulate(y Int16x16, z Int16x16) Int32x8

// SaturatedPairDotProdAccumulate performs dot products on pairs of elements of y and z and accumulates the results to x.
//
// Asm: VPDPWSSDS, CPU Feature: AVX512EVEX
func (x Int32x16) SaturatedPairDotProdAccumulate(y Int16x32, z Int16x32) Int32x16

/* SaturatedPairwiseAdd */

// SaturatedPairwiseAdd horizontally adds adjacent pairs of elements with saturation.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDSW, CPU Feature: AVX
func (x Int16x8) SaturatedPairwiseAdd(y Int16x8) Int16x8

// SaturatedPairwiseAdd horizontally adds adjacent pairs of elements with saturation.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0+y1, y2+y3, ..., x0+x1, x2+x3, ...].
//
// Asm: VPHADDSW, CPU Feature: AVX2
func (x Int16x16) SaturatedPairwiseAdd(y Int16x16) Int16x16

/* SaturatedPairwiseSub */

// SaturatedPairwiseSub horizontally subtracts adjacent pairs of elements with saturation.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBSW, CPU Feature: AVX
func (x Int16x8) SaturatedPairwiseSub(y Int16x8) Int16x8

// SaturatedPairwiseSub horizontally subtracts adjacent pairs of elements with saturation.
// For x = [x0, x1, x2, x3, ...] and y = [y0, y1, y2, y3, ...], the result is [y0-y1, y2-y3, ..., x0-x1, x2-x3, ...].
//
// Asm: VPHSUBSW, CPU Feature: AVX2
func (x Int16x16) SaturatedPairwiseSub(y Int16x16) Int16x16

/* SaturatedSub */

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX
func (x Int8x16) SaturatedSub(y Int8x16) Int8x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX2
func (x Int8x32) SaturatedSub(y Int8x32) Int8x32

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Int8x64) SaturatedSub(y Int8x64) Int8x64

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX
func (x Int16x8) SaturatedSub(y Int16x8) Int16x8

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX2
func (x Int16x16) SaturatedSub(y Int16x16) Int16x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Int16x32) SaturatedSub(y Int16x32) Int16x32

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX
func (x Uint8x16) SaturatedSub(y Uint8x16) Uint8x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX2
func (x Uint8x32) SaturatedSub(y Uint8x32) Uint8x32

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSB, CPU Feature: AVX512EVEX
func (x Uint8x64) SaturatedSub(y Uint8x64) Uint8x64

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX
func (x Uint16x8) SaturatedSub(y Uint16x8) Uint16x8

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX2
func (x Uint16x16) SaturatedSub(y Uint16x16) Uint16x16

// SaturatedSub subtracts corresponding elements of two vectors with saturation.
//
// Asm: VPSUBSW, CPU Feature: AVX512EVEX
func (x Uint16x32) SaturatedSub(y Uint16x32) Uint16x32

/* SaturatedUnsignedSignedPairDotProd */

// SaturatedPairDotProd multiplies the elements and add the pairs together with saturation,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDUBSW, CPU Feature: AVX
func (x Uint8x16) SaturatedUnsignedSignedPairDotProd(y Int8x16) Int16x8

// SaturatedPairDotProd multiplies the elements and add the pairs together with saturation,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDUBSW, CPU Feature: AVX2
func (x Uint8x32) SaturatedUnsignedSignedPairDotProd(y Int8x32) Int16x16

// SaturatedPairDotProd multiplies the elements and add the pairs together with saturation,
// yielding a vector of half as many elements with twice the input element size.
//
// Asm: VPMADDUBSW, CPU Feature: AVX512EVEX
func (x Uint8x64) SaturatedUnsignedSignedPairDotProd(y Int8x64) Int16x32

/* SaturatedUnsignedSignedQuadDotProdAccumulate */

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX_VNNI
func (x Int32x4) SaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16) Int32x4

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX_VNNI
func (x Int32x8) SaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32) Int32x8

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Int32x16) SaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64) Int32x16

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX_VNNI
func (x Uint32x4) SaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16) Uint32x4

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX_VNNI
func (x Uint32x8) SaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32) Uint32x8

// SaturatedUnsignedSignedQuadDotProdAccumulate multiplies performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSDS, CPU Feature: AVX512EVEX
func (x Uint32x16) SaturatedUnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64) Uint32x16

/* SetElem */

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRB, CPU Feature: AVX
func (x Int8x16) SetElem(imm uint8, y int8) Int8x16

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRW, CPU Feature: AVX
func (x Int16x8) SetElem(imm uint8, y int16) Int16x8

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRD, CPU Feature: AVX
func (x Int32x4) SetElem(imm uint8, y int32) Int32x4

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRQ, CPU Feature: AVX
func (x Int64x2) SetElem(imm uint8, y int64) Int64x2

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRB, CPU Feature: AVX
func (x Uint8x16) SetElem(imm uint8, y uint8) Uint8x16

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRW, CPU Feature: AVX
func (x Uint16x8) SetElem(imm uint8, y uint16) Uint16x8

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRD, CPU Feature: AVX
func (x Uint32x4) SetElem(imm uint8, y uint32) Uint32x4

// SetElem sets a single constant-indexed element's value.
//
// Asm: VPINSRQ, CPU Feature: AVX
func (x Uint64x2) SetElem(imm uint8, y uint64) Uint64x2

/* ShiftAllLeft */

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLW, CPU Feature: AVX
func (x Int16x8) ShiftAllLeft(y uint64) Int16x8

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLW, CPU Feature: AVX2
func (x Int16x16) ShiftAllLeft(y uint64) Int16x16

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLD, CPU Feature: AVX
func (x Int32x4) ShiftAllLeft(y uint64) Int32x4

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLD, CPU Feature: AVX2
func (x Int32x8) ShiftAllLeft(y uint64) Int32x8

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX
func (x Int64x2) ShiftAllLeft(y uint64) Int64x2

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX2
func (x Int64x4) ShiftAllLeft(y uint64) Int64x4

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftAllLeft(y uint64) Int64x8

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLW, CPU Feature: AVX
func (x Uint16x8) ShiftAllLeft(y uint64) Uint16x8

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLW, CPU Feature: AVX2
func (x Uint16x16) ShiftAllLeft(y uint64) Uint16x16

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLD, CPU Feature: AVX
func (x Uint32x4) ShiftAllLeft(y uint64) Uint32x4

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLD, CPU Feature: AVX2
func (x Uint32x8) ShiftAllLeft(y uint64) Uint32x8

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX
func (x Uint64x2) ShiftAllLeft(y uint64) Uint64x2

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX2
func (x Uint64x4) ShiftAllLeft(y uint64) Uint64x4

// ShiftAllLeft shifts each element to the left by the specified number of bits. Emptied lower bits are zeroed.
//
// Asm: VPSLLQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftAllLeft(y uint64) Uint64x8

/* ShiftAllLeftAndFillUpperFrom */

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int16x8) Int16x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int16x16) Int16x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int16x32) Int16x32

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Int32x4) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int32x4) Int32x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Int32x8) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int32x8) Int32x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int32x16) Int32x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Int64x2) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int64x2) Int64x2

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Int64x4) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int64x4) Int64x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftAllLeftAndFillUpperFrom(imm uint8, y Int64x8) Int64x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint16x8) Uint16x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint16x16) Uint16x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint16x32) Uint16x32

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Uint32x4) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint32x4) Uint32x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Uint32x8) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint32x8) Uint32x8

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint32x16) Uint32x16

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint64x2) Uint64x2

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint64x4) Uint64x4

// ShiftAllLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the upper bits of y to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftAllLeftAndFillUpperFrom(imm uint8, y Uint64x8) Uint64x8

/* ShiftAllRight */

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLW, CPU Feature: AVX
func (x Int16x8) ShiftAllRight(y uint64) Int16x8

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLW, CPU Feature: AVX2
func (x Int16x16) ShiftAllRight(y uint64) Int16x16

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLD, CPU Feature: AVX
func (x Int32x4) ShiftAllRight(y uint64) Int32x4

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLD, CPU Feature: AVX2
func (x Int32x8) ShiftAllRight(y uint64) Int32x8

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX
func (x Int64x2) ShiftAllRight(y uint64) Int64x2

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX2
func (x Int64x4) ShiftAllRight(y uint64) Int64x4

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftAllRight(y uint64) Int64x8

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLW, CPU Feature: AVX
func (x Uint16x8) ShiftAllRight(y uint64) Uint16x8

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLW, CPU Feature: AVX2
func (x Uint16x16) ShiftAllRight(y uint64) Uint16x16

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLD, CPU Feature: AVX
func (x Uint32x4) ShiftAllRight(y uint64) Uint32x4

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLD, CPU Feature: AVX2
func (x Uint32x8) ShiftAllRight(y uint64) Uint32x8

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX
func (x Uint64x2) ShiftAllRight(y uint64) Uint64x2

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX2
func (x Uint64x4) ShiftAllRight(y uint64) Uint64x4

// ShiftAllRight shifts each element to the right by the specified number of bits. Emptied upper bits are zeroed.
//
// Asm: VPSRLQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftAllRight(y uint64) Uint64x8

/* ShiftAllRightAndFillUpperFrom */

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftAllRightAndFillUpperFrom(imm uint8, y Int16x8) Int16x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftAllRightAndFillUpperFrom(imm uint8, y Int16x16) Int16x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftAllRightAndFillUpperFrom(imm uint8, y Int16x32) Int16x32

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Int32x4) ShiftAllRightAndFillUpperFrom(imm uint8, y Int32x4) Int32x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Int32x8) ShiftAllRightAndFillUpperFrom(imm uint8, y Int32x8) Int32x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftAllRightAndFillUpperFrom(imm uint8, y Int32x16) Int32x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Int64x2) ShiftAllRightAndFillUpperFrom(imm uint8, y Int64x2) Int64x2

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Int64x4) ShiftAllRightAndFillUpperFrom(imm uint8, y Int64x4) Int64x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftAllRightAndFillUpperFrom(imm uint8, y Int64x8) Int64x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint16x8) Uint16x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint16x16) Uint16x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint16x32) Uint16x32

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Uint32x4) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint32x4) Uint32x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Uint32x8) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint32x8) Uint32x8

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint32x16) Uint32x16

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Uint64x2) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint64x2) Uint64x2

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Uint64x4) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint64x4) Uint64x4

// ShiftAllRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// immediate(only the lower 5 bits are used), and then copies the lower bits of y to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftAllRightAndFillUpperFrom(imm uint8, y Uint64x8) Uint64x8

/* ShiftAllRightSignExtended */

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAW, CPU Feature: AVX
func (x Int16x8) ShiftAllRightSignExtended(y uint64) Int16x8

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAW, CPU Feature: AVX2
func (x Int16x16) ShiftAllRightSignExtended(y uint64) Int16x16

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAD, CPU Feature: AVX
func (x Int32x4) ShiftAllRightSignExtended(y uint64) Int32x4

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAD, CPU Feature: AVX2
func (x Int32x8) ShiftAllRightSignExtended(y uint64) Int32x8

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAQ, CPU Feature: AVX512EVEX
func (x Int64x2) ShiftAllRightSignExtended(y uint64) Int64x2

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAQ, CPU Feature: AVX512EVEX
func (x Int64x4) ShiftAllRightSignExtended(y uint64) Int64x4

// ShiftAllRightSignExtended shifts each element to the right by the specified number of bits. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftAllRightSignExtended(y uint64) Int64x8

/* ShiftLeft */

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftLeft(y Int16x8) Int16x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftLeft(y Int16x16) Int16x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftLeft(y Int16x32) Int16x32

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX2
func (x Int32x4) ShiftLeft(y Int32x4) Int32x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX2
func (x Int32x8) ShiftLeft(y Int32x8) Int32x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftLeft(y Int32x16) Int32x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX2
func (x Int64x2) ShiftLeft(y Int64x2) Int64x2

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX2
func (x Int64x4) ShiftLeft(y Int64x4) Int64x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftLeft(y Int64x8) Int64x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftLeft(y Uint16x8) Uint16x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftLeft(y Uint16x16) Uint16x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftLeft(y Uint16x32) Uint16x32

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX2
func (x Uint32x4) ShiftLeft(y Uint32x4) Uint32x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX2
func (x Uint32x8) ShiftLeft(y Uint32x8) Uint32x8

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftLeft(y Uint32x16) Uint32x16

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX2
func (x Uint64x2) ShiftLeft(y Uint64x2) Uint64x2

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX2
func (x Uint64x4) ShiftLeft(y Uint64x4) Uint64x4

// ShiftLeft shifts each element in x to the left by the number of bits specified in y's corresponding elements. Emptied lower bits are zeroed.
//
// Asm: VPSLLVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftLeft(y Uint64x8) Uint64x8

/* ShiftLeftAndFillUpperFrom */

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftLeftAndFillUpperFrom(y Int16x8, z Int16x8) Int16x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftLeftAndFillUpperFrom(y Int16x16, z Int16x16) Int16x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftLeftAndFillUpperFrom(y Int16x32, z Int16x32) Int16x32

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Int32x4) ShiftLeftAndFillUpperFrom(y Int32x4, z Int32x4) Int32x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Int32x8) ShiftLeftAndFillUpperFrom(y Int32x8, z Int32x8) Int32x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftLeftAndFillUpperFrom(y Int32x16, z Int32x16) Int32x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Int64x2) ShiftLeftAndFillUpperFrom(y Int64x2, z Int64x2) Int64x2

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Int64x4) ShiftLeftAndFillUpperFrom(y Int64x4, z Int64x4) Int64x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftLeftAndFillUpperFrom(y Int64x8, z Int64x8) Int64x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftLeftAndFillUpperFrom(y Uint16x8, z Uint16x8) Uint16x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftLeftAndFillUpperFrom(y Uint16x16, z Uint16x16) Uint16x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftLeftAndFillUpperFrom(y Uint16x32, z Uint16x32) Uint16x32

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Uint32x4) ShiftLeftAndFillUpperFrom(y Uint32x4, z Uint32x4) Uint32x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Uint32x8) ShiftLeftAndFillUpperFrom(y Uint32x8, z Uint32x8) Uint32x8

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftLeftAndFillUpperFrom(y Uint32x16, z Uint32x16) Uint32x16

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) ShiftLeftAndFillUpperFrom(y Uint64x2, z Uint64x2) Uint64x2

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) ShiftLeftAndFillUpperFrom(y Uint64x4, z Uint64x4) Uint64x4

// ShiftLeftAndFillUpperFrom shifts each element of x to the left by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the upper bits of z to the emptied lower bits of the shifted x.
//
// Asm: VPSHLDVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftLeftAndFillUpperFrom(y Uint64x8, z Uint64x8) Uint64x8

/* ShiftRight */

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftRight(y Int16x8) Int16x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftRight(y Int16x16) Int16x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftRight(y Int16x32) Int16x32

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX2
func (x Int32x4) ShiftRight(y Int32x4) Int32x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX2
func (x Int32x8) ShiftRight(y Int32x8) Int32x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftRight(y Int32x16) Int32x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX2
func (x Int64x2) ShiftRight(y Int64x2) Int64x2

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX2
func (x Int64x4) ShiftRight(y Int64x4) Int64x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftRight(y Int64x8) Int64x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftRight(y Uint16x8) Uint16x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftRight(y Uint16x16) Uint16x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftRight(y Uint16x32) Uint16x32

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX2
func (x Uint32x4) ShiftRight(y Uint32x4) Uint32x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX2
func (x Uint32x8) ShiftRight(y Uint32x8) Uint32x8

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftRight(y Uint32x16) Uint32x16

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX2
func (x Uint64x2) ShiftRight(y Uint64x2) Uint64x2

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX2
func (x Uint64x4) ShiftRight(y Uint64x4) Uint64x4

// ShiftRight shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are zeroed.
//
// Asm: VPSRLVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftRight(y Uint64x8) Uint64x8

/* ShiftRightAndFillUpperFrom */

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftRightAndFillUpperFrom(y Int16x8, z Int16x8) Int16x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftRightAndFillUpperFrom(y Int16x16, z Int16x16) Int16x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftRightAndFillUpperFrom(y Int16x32, z Int16x32) Int16x32

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Int32x4) ShiftRightAndFillUpperFrom(y Int32x4, z Int32x4) Int32x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Int32x8) ShiftRightAndFillUpperFrom(y Int32x8, z Int32x8) Int32x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftRightAndFillUpperFrom(y Int32x16, z Int32x16) Int32x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Int64x2) ShiftRightAndFillUpperFrom(y Int64x2, z Int64x2) Int64x2

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Int64x4) ShiftRightAndFillUpperFrom(y Int64x4, z Int64x4) Int64x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftRightAndFillUpperFrom(y Int64x8, z Int64x8) Int64x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftRightAndFillUpperFrom(y Uint16x8, z Uint16x8) Uint16x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftRightAndFillUpperFrom(y Uint16x16, z Uint16x16) Uint16x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftRightAndFillUpperFrom(y Uint16x32, z Uint16x32) Uint16x32

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Uint32x4) ShiftRightAndFillUpperFrom(y Uint32x4, z Uint32x4) Uint32x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Uint32x8) ShiftRightAndFillUpperFrom(y Uint32x8, z Uint32x8) Uint32x8

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftRightAndFillUpperFrom(y Uint32x16, z Uint32x16) Uint32x16

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) ShiftRightAndFillUpperFrom(y Uint64x2, z Uint64x2) Uint64x2

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) ShiftRightAndFillUpperFrom(y Uint64x4, z Uint64x4) Uint64x4

// ShiftRightAndFillUpperFrom shifts each element of x to the right by the number of bits specified by the
// corresponding elements in y(only the lower 5 bits are used), and then copies the lower bits of z to the emptied upper bits of the shifted x.
//
// Asm: VPSHRDVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftRightAndFillUpperFrom(y Uint64x8, z Uint64x8) Uint64x8

/* ShiftRightSignExtended */

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Int16x8) ShiftRightSignExtended(y Int16x8) Int16x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Int16x16) ShiftRightSignExtended(y Int16x16) Int16x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Int16x32) ShiftRightSignExtended(y Int16x32) Int16x32

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX2
func (x Int32x4) ShiftRightSignExtended(y Int32x4) Int32x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX2
func (x Int32x8) ShiftRightSignExtended(y Int32x8) Int32x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Int32x16) ShiftRightSignExtended(y Int32x16) Int32x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Int64x2) ShiftRightSignExtended(y Int64x2) Int64x2

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Int64x4) ShiftRightSignExtended(y Int64x4) Int64x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Int64x8) ShiftRightSignExtended(y Int64x8) Int64x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Uint16x8) ShiftRightSignExtended(y Uint16x8) Uint16x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Uint16x16) ShiftRightSignExtended(y Uint16x16) Uint16x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVW, CPU Feature: AVX512EVEX
func (x Uint16x32) ShiftRightSignExtended(y Uint16x32) Uint16x32

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX2
func (x Uint32x4) ShiftRightSignExtended(y Uint32x4) Uint32x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX2
func (x Uint32x8) ShiftRightSignExtended(y Uint32x8) Uint32x8

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVD, CPU Feature: AVX512EVEX
func (x Uint32x16) ShiftRightSignExtended(y Uint32x16) Uint32x16

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Uint64x2) ShiftRightSignExtended(y Uint64x2) Uint64x2

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Uint64x4) ShiftRightSignExtended(y Uint64x4) Uint64x4

// ShiftRightSignExtended shifts each element in x to the right by the number of bits specified in y's corresponding elements. Emptied upper bits are filled with the sign bit.
//
// Asm: VPSRAVQ, CPU Feature: AVX512EVEX
func (x Uint64x8) ShiftRightSignExtended(y Uint64x8) Uint64x8

/* Sign */

// Sign returns the product of the first operand with -1, 0, or 1,
// whichever constant is nearest to the value of the second operand.
//
// Asm: VPSIGNB, CPU Feature: AVX
func (x Int8x16) Sign(y Int8x16) Int8x16

// Sign returns the product of the first operand with -1, 0, or 1,
// whichever constant is nearest to the value of the second operand.
//
// Asm: VPSIGNB, CPU Feature: AVX2
func (x Int8x32) Sign(y Int8x32) Int8x32

// Sign returns the product of the first operand with -1, 0, or 1,
// whichever constant is nearest to the value of the second operand.
//
// Asm: VPSIGNW, CPU Feature: AVX
func (x Int16x8) Sign(y Int16x8) Int16x8

// Sign returns the product of the first operand with -1, 0, or 1,
// whichever constant is nearest to the value of the second operand.
//
// Asm: VPSIGNW, CPU Feature: AVX2
func (x Int16x16) Sign(y Int16x16) Int16x16

// Sign returns the product of the first operand with -1, 0, or 1,
// whichever constant is nearest to the value of the second operand.
//
// Asm: VPSIGND, CPU Feature: AVX
func (x Int32x4) Sign(y Int32x4) Int32x4

// Sign returns the product of the first operand with -1, 0, or 1,
// whichever constant is nearest to the value of the second operand.
//
// Asm: VPSIGND, CPU Feature: AVX2
func (x Int32x8) Sign(y Int32x8) Int32x8

/* Sqrt */

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPS, CPU Feature: AVX
func (x Float32x4) Sqrt() Float32x4

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPS, CPU Feature: AVX
func (x Float32x8) Sqrt() Float32x8

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPS, CPU Feature: AVX512EVEX
func (x Float32x16) Sqrt() Float32x16

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPD, CPU Feature: AVX
func (x Float64x2) Sqrt() Float64x2

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPD, CPU Feature: AVX
func (x Float64x4) Sqrt() Float64x4

// Sqrt computes the square root of each element.
//
// Asm: VSQRTPD, CPU Feature: AVX512EVEX
func (x Float64x8) Sqrt() Float64x8

/* Sub */

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPS, CPU Feature: AVX
func (x Float32x4) Sub(y Float32x4) Float32x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPS, CPU Feature: AVX
func (x Float32x8) Sub(y Float32x8) Float32x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPS, CPU Feature: AVX512EVEX
func (x Float32x16) Sub(y Float32x16) Float32x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPD, CPU Feature: AVX
func (x Float64x2) Sub(y Float64x2) Float64x2

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPD, CPU Feature: AVX
func (x Float64x4) Sub(y Float64x4) Float64x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VSUBPD, CPU Feature: AVX512EVEX
func (x Float64x8) Sub(y Float64x8) Float64x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX
func (x Int8x16) Sub(y Int8x16) Int8x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX2
func (x Int8x32) Sub(y Int8x32) Int8x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Int8x64) Sub(y Int8x64) Int8x64

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX
func (x Int16x8) Sub(y Int16x8) Int16x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX2
func (x Int16x16) Sub(y Int16x16) Int16x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Int16x32) Sub(y Int16x32) Int16x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX
func (x Int32x4) Sub(y Int32x4) Int32x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX2
func (x Int32x8) Sub(y Int32x8) Int32x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Int32x16) Sub(y Int32x16) Int32x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX
func (x Int64x2) Sub(y Int64x2) Int64x2

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX2
func (x Int64x4) Sub(y Int64x4) Int64x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Int64x8) Sub(y Int64x8) Int64x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX
func (x Uint8x16) Sub(y Uint8x16) Uint8x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX2
func (x Uint8x32) Sub(y Uint8x32) Uint8x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBB, CPU Feature: AVX512EVEX
func (x Uint8x64) Sub(y Uint8x64) Uint8x64

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX
func (x Uint16x8) Sub(y Uint16x8) Uint16x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX2
func (x Uint16x16) Sub(y Uint16x16) Uint16x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBW, CPU Feature: AVX512EVEX
func (x Uint16x32) Sub(y Uint16x32) Uint16x32

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX
func (x Uint32x4) Sub(y Uint32x4) Uint32x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX2
func (x Uint32x8) Sub(y Uint32x8) Uint32x8

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBD, CPU Feature: AVX512EVEX
func (x Uint32x16) Sub(y Uint32x16) Uint32x16

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX
func (x Uint64x2) Sub(y Uint64x2) Uint64x2

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX2
func (x Uint64x4) Sub(y Uint64x4) Uint64x4

// Sub subtracts corresponding elements of two vectors.
//
// Asm: VPSUBQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Sub(y Uint64x8) Uint64x8

/* Trunc */

// Trunc truncates elements towards zero.
// Const Immediate = 3.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x4) Trunc() Float32x4

// Trunc truncates elements towards zero.
// Const Immediate = 3.
//
// Asm: VROUNDPS, CPU Feature: AVX
func (x Float32x8) Trunc() Float32x8

// Trunc truncates elements towards zero.
// Const Immediate = 3.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x2) Trunc() Float64x2

// Trunc truncates elements towards zero.
// Const Immediate = 3.
//
// Asm: VROUNDPD, CPU Feature: AVX
func (x Float64x4) Trunc() Float64x4

/* TruncSuppressExceptionWithPrecision */

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) TruncSuppressExceptionWithPrecision(imm8 uint8) Float32x4

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) TruncSuppressExceptionWithPrecision(imm8 uint8) Float32x8

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) TruncSuppressExceptionWithPrecision(imm8 uint8) Float32x16

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) TruncSuppressExceptionWithPrecision(imm8 uint8) Float64x2

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) TruncSuppressExceptionWithPrecision(imm8 uint8) Float64x4

// TruncSuppressExceptionWithPrecision truncates elements with specified precision, suppressing exceptions.
// Const Immediate = 11.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) TruncSuppressExceptionWithPrecision(imm8 uint8) Float64x8

/* TruncWithPrecision */

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x4) TruncWithPrecision(imm8 uint8) Float32x4

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x8) TruncWithPrecision(imm8 uint8) Float32x8

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPS, CPU Feature: AVX512EVEX
func (x Float32x16) TruncWithPrecision(imm8 uint8) Float32x16

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x2) TruncWithPrecision(imm8 uint8) Float64x2

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x4) TruncWithPrecision(imm8 uint8) Float64x4

// TruncWithPrecision truncates elements with specified precision.
// Const Immediate = 3.
//
// Asm: VRNDSCALEPD, CPU Feature: AVX512EVEX
func (x Float64x8) TruncWithPrecision(imm8 uint8) Float64x8

/* UnsignedSignedQuadDotProdAccumulate */

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX_VNNI
func (x Int32x4) UnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16) Int32x4

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX_VNNI
func (x Int32x8) UnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32) Int32x8

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Int32x16) UnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64) Int32x16

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX_VNNI
func (x Uint32x4) UnsignedSignedQuadDotProdAccumulate(y Uint8x16, z Int8x16) Uint32x4

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX_VNNI
func (x Uint32x8) UnsignedSignedQuadDotProdAccumulate(y Uint8x32, z Int8x32) Uint32x8

// UnsignedSignedQuadDotProdAccumulate performs dot products on groups of 4 elements of y and z and accumulates the results to x.
//
// Asm: VPDPBUSD, CPU Feature: AVX512EVEX
func (x Uint32x16) UnsignedSignedQuadDotProdAccumulate(y Uint8x64, z Int8x64) Uint32x16

/* Xor */

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VXORPS, CPU Feature: AVX
func (x Float32x4) Xor(y Float32x4) Float32x4

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VXORPS, CPU Feature: AVX
func (x Float32x8) Xor(y Float32x8) Float32x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPS, CPU Feature: AVX512EVEX
func (x Float32x16) Xor(y Float32x16) Float32x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VXORPD, CPU Feature: AVX
func (x Float64x2) Xor(y Float64x2) Float64x2

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VXORPD, CPU Feature: AVX
func (x Float64x4) Xor(y Float64x4) Float64x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VXORPD, CPU Feature: AVX512EVEX
func (x Float64x8) Xor(y Float64x8) Float64x8

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Int8x16) Xor(y Int8x16) Int8x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Int8x32) Xor(y Int8x32) Int8x32

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Int16x8) Xor(y Int16x8) Int16x8

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Int16x16) Xor(y Int16x16) Int16x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Int32x4) Xor(y Int32x4) Int32x4

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Int32x8) Xor(y Int32x8) Int32x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Int32x16) Xor(y Int32x16) Int32x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Int64x2) Xor(y Int64x2) Int64x2

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Int64x4) Xor(y Int64x4) Int64x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Int64x8) Xor(y Int64x8) Int64x8

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Uint8x16) Xor(y Uint8x16) Uint8x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Uint8x32) Xor(y Uint8x32) Uint8x32

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Uint16x8) Xor(y Uint16x8) Uint16x8

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Uint16x16) Xor(y Uint16x16) Uint16x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Uint32x4) Xor(y Uint32x4) Uint32x4

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Uint32x8) Xor(y Uint32x8) Uint32x8

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORD, CPU Feature: AVX512EVEX
func (x Uint32x16) Xor(y Uint32x16) Uint32x16

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX
func (x Uint64x2) Xor(y Uint64x2) Uint64x2

// Xor performs a bitwise XOR operation between two vectors.
//
// Asm: VPXOR, CPU Feature: AVX2
func (x Uint64x4) Xor(y Uint64x4) Uint64x4

// Xor performs a masked bitwise XOR operation between two vectors.
//
// Asm: VPXORQ, CPU Feature: AVX512EVEX
func (x Uint64x8) Xor(y Uint64x8) Uint64x8

// Float64x2 converts from Float32x4 to Float64x2
func (from Float32x4) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Float32x4 to Int8x16
func (from Float32x4) AsInt8x16() (to Int8x16)

// Int16x8 converts from Float32x4 to Int16x8
func (from Float32x4) AsInt16x8() (to Int16x8)

// Int32x4 converts from Float32x4 to Int32x4
func (from Float32x4) AsInt32x4() (to Int32x4)

// Int64x2 converts from Float32x4 to Int64x2
func (from Float32x4) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Float32x4 to Uint8x16
func (from Float32x4) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Float32x4 to Uint16x8
func (from Float32x4) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Float32x4 to Uint32x4
func (from Float32x4) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Float32x4 to Uint64x2
func (from Float32x4) AsUint64x2() (to Uint64x2)

// Float64x4 converts from Float32x8 to Float64x4
func (from Float32x8) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Float32x8 to Int8x32
func (from Float32x8) AsInt8x32() (to Int8x32)

// Int16x16 converts from Float32x8 to Int16x16
func (from Float32x8) AsInt16x16() (to Int16x16)

// Int32x8 converts from Float32x8 to Int32x8
func (from Float32x8) AsInt32x8() (to Int32x8)

// Int64x4 converts from Float32x8 to Int64x4
func (from Float32x8) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Float32x8 to Uint8x32
func (from Float32x8) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Float32x8 to Uint16x16
func (from Float32x8) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Float32x8 to Uint32x8
func (from Float32x8) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Float32x8 to Uint64x4
func (from Float32x8) AsUint64x4() (to Uint64x4)

// Float64x8 converts from Float32x16 to Float64x8
func (from Float32x16) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Float32x16 to Int8x64
func (from Float32x16) AsInt8x64() (to Int8x64)

// Int16x32 converts from Float32x16 to Int16x32
func (from Float32x16) AsInt16x32() (to Int16x32)

// Int32x16 converts from Float32x16 to Int32x16
func (from Float32x16) AsInt32x16() (to Int32x16)

// Int64x8 converts from Float32x16 to Int64x8
func (from Float32x16) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Float32x16 to Uint8x64
func (from Float32x16) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Float32x16 to Uint16x32
func (from Float32x16) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Float32x16 to Uint32x16
func (from Float32x16) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Float32x16 to Uint64x8
func (from Float32x16) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Float64x2 to Float32x4
func (from Float64x2) AsFloat32x4() (to Float32x4)

// Int8x16 converts from Float64x2 to Int8x16
func (from Float64x2) AsInt8x16() (to Int8x16)

// Int16x8 converts from Float64x2 to Int16x8
func (from Float64x2) AsInt16x8() (to Int16x8)

// Int32x4 converts from Float64x2 to Int32x4
func (from Float64x2) AsInt32x4() (to Int32x4)

// Int64x2 converts from Float64x2 to Int64x2
func (from Float64x2) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Float64x2 to Uint8x16
func (from Float64x2) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Float64x2 to Uint16x8
func (from Float64x2) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Float64x2 to Uint32x4
func (from Float64x2) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Float64x2 to Uint64x2
func (from Float64x2) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Float64x4 to Float32x8
func (from Float64x4) AsFloat32x8() (to Float32x8)

// Int8x32 converts from Float64x4 to Int8x32
func (from Float64x4) AsInt8x32() (to Int8x32)

// Int16x16 converts from Float64x4 to Int16x16
func (from Float64x4) AsInt16x16() (to Int16x16)

// Int32x8 converts from Float64x4 to Int32x8
func (from Float64x4) AsInt32x8() (to Int32x8)

// Int64x4 converts from Float64x4 to Int64x4
func (from Float64x4) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Float64x4 to Uint8x32
func (from Float64x4) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Float64x4 to Uint16x16
func (from Float64x4) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Float64x4 to Uint32x8
func (from Float64x4) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Float64x4 to Uint64x4
func (from Float64x4) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Float64x8 to Float32x16
func (from Float64x8) AsFloat32x16() (to Float32x16)

// Int8x64 converts from Float64x8 to Int8x64
func (from Float64x8) AsInt8x64() (to Int8x64)

// Int16x32 converts from Float64x8 to Int16x32
func (from Float64x8) AsInt16x32() (to Int16x32)

// Int32x16 converts from Float64x8 to Int32x16
func (from Float64x8) AsInt32x16() (to Int32x16)

// Int64x8 converts from Float64x8 to Int64x8
func (from Float64x8) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Float64x8 to Uint8x64
func (from Float64x8) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Float64x8 to Uint16x32
func (from Float64x8) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Float64x8 to Uint32x16
func (from Float64x8) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Float64x8 to Uint64x8
func (from Float64x8) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Int8x16 to Float32x4
func (from Int8x16) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Int8x16 to Float64x2
func (from Int8x16) AsFloat64x2() (to Float64x2)

// Int16x8 converts from Int8x16 to Int16x8
func (from Int8x16) AsInt16x8() (to Int16x8)

// Int32x4 converts from Int8x16 to Int32x4
func (from Int8x16) AsInt32x4() (to Int32x4)

// Int64x2 converts from Int8x16 to Int64x2
func (from Int8x16) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Int8x16 to Uint8x16
func (from Int8x16) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Int8x16 to Uint16x8
func (from Int8x16) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Int8x16 to Uint32x4
func (from Int8x16) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Int8x16 to Uint64x2
func (from Int8x16) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Int8x32 to Float32x8
func (from Int8x32) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Int8x32 to Float64x4
func (from Int8x32) AsFloat64x4() (to Float64x4)

// Int16x16 converts from Int8x32 to Int16x16
func (from Int8x32) AsInt16x16() (to Int16x16)

// Int32x8 converts from Int8x32 to Int32x8
func (from Int8x32) AsInt32x8() (to Int32x8)

// Int64x4 converts from Int8x32 to Int64x4
func (from Int8x32) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Int8x32 to Uint8x32
func (from Int8x32) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Int8x32 to Uint16x16
func (from Int8x32) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Int8x32 to Uint32x8
func (from Int8x32) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Int8x32 to Uint64x4
func (from Int8x32) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Int8x64 to Float32x16
func (from Int8x64) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Int8x64 to Float64x8
func (from Int8x64) AsFloat64x8() (to Float64x8)

// Int16x32 converts from Int8x64 to Int16x32
func (from Int8x64) AsInt16x32() (to Int16x32)

// Int32x16 converts from Int8x64 to Int32x16
func (from Int8x64) AsInt32x16() (to Int32x16)

// Int64x8 converts from Int8x64 to Int64x8
func (from Int8x64) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Int8x64 to Uint8x64
func (from Int8x64) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Int8x64 to Uint16x32
func (from Int8x64) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Int8x64 to Uint32x16
func (from Int8x64) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Int8x64 to Uint64x8
func (from Int8x64) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Int16x8 to Float32x4
func (from Int16x8) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Int16x8 to Float64x2
func (from Int16x8) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Int16x8 to Int8x16
func (from Int16x8) AsInt8x16() (to Int8x16)

// Int32x4 converts from Int16x8 to Int32x4
func (from Int16x8) AsInt32x4() (to Int32x4)

// Int64x2 converts from Int16x8 to Int64x2
func (from Int16x8) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Int16x8 to Uint8x16
func (from Int16x8) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Int16x8 to Uint16x8
func (from Int16x8) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Int16x8 to Uint32x4
func (from Int16x8) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Int16x8 to Uint64x2
func (from Int16x8) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Int16x16 to Float32x8
func (from Int16x16) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Int16x16 to Float64x4
func (from Int16x16) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Int16x16 to Int8x32
func (from Int16x16) AsInt8x32() (to Int8x32)

// Int32x8 converts from Int16x16 to Int32x8
func (from Int16x16) AsInt32x8() (to Int32x8)

// Int64x4 converts from Int16x16 to Int64x4
func (from Int16x16) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Int16x16 to Uint8x32
func (from Int16x16) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Int16x16 to Uint16x16
func (from Int16x16) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Int16x16 to Uint32x8
func (from Int16x16) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Int16x16 to Uint64x4
func (from Int16x16) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Int16x32 to Float32x16
func (from Int16x32) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Int16x32 to Float64x8
func (from Int16x32) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Int16x32 to Int8x64
func (from Int16x32) AsInt8x64() (to Int8x64)

// Int32x16 converts from Int16x32 to Int32x16
func (from Int16x32) AsInt32x16() (to Int32x16)

// Int64x8 converts from Int16x32 to Int64x8
func (from Int16x32) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Int16x32 to Uint8x64
func (from Int16x32) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Int16x32 to Uint16x32
func (from Int16x32) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Int16x32 to Uint32x16
func (from Int16x32) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Int16x32 to Uint64x8
func (from Int16x32) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Int32x4 to Float32x4
func (from Int32x4) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Int32x4 to Float64x2
func (from Int32x4) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Int32x4 to Int8x16
func (from Int32x4) AsInt8x16() (to Int8x16)

// Int16x8 converts from Int32x4 to Int16x8
func (from Int32x4) AsInt16x8() (to Int16x8)

// Int64x2 converts from Int32x4 to Int64x2
func (from Int32x4) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Int32x4 to Uint8x16
func (from Int32x4) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Int32x4 to Uint16x8
func (from Int32x4) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Int32x4 to Uint32x4
func (from Int32x4) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Int32x4 to Uint64x2
func (from Int32x4) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Int32x8 to Float32x8
func (from Int32x8) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Int32x8 to Float64x4
func (from Int32x8) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Int32x8 to Int8x32
func (from Int32x8) AsInt8x32() (to Int8x32)

// Int16x16 converts from Int32x8 to Int16x16
func (from Int32x8) AsInt16x16() (to Int16x16)

// Int64x4 converts from Int32x8 to Int64x4
func (from Int32x8) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Int32x8 to Uint8x32
func (from Int32x8) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Int32x8 to Uint16x16
func (from Int32x8) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Int32x8 to Uint32x8
func (from Int32x8) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Int32x8 to Uint64x4
func (from Int32x8) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Int32x16 to Float32x16
func (from Int32x16) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Int32x16 to Float64x8
func (from Int32x16) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Int32x16 to Int8x64
func (from Int32x16) AsInt8x64() (to Int8x64)

// Int16x32 converts from Int32x16 to Int16x32
func (from Int32x16) AsInt16x32() (to Int16x32)

// Int64x8 converts from Int32x16 to Int64x8
func (from Int32x16) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Int32x16 to Uint8x64
func (from Int32x16) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Int32x16 to Uint16x32
func (from Int32x16) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Int32x16 to Uint32x16
func (from Int32x16) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Int32x16 to Uint64x8
func (from Int32x16) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Int64x2 to Float32x4
func (from Int64x2) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Int64x2 to Float64x2
func (from Int64x2) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Int64x2 to Int8x16
func (from Int64x2) AsInt8x16() (to Int8x16)

// Int16x8 converts from Int64x2 to Int16x8
func (from Int64x2) AsInt16x8() (to Int16x8)

// Int32x4 converts from Int64x2 to Int32x4
func (from Int64x2) AsInt32x4() (to Int32x4)

// Uint8x16 converts from Int64x2 to Uint8x16
func (from Int64x2) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Int64x2 to Uint16x8
func (from Int64x2) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Int64x2 to Uint32x4
func (from Int64x2) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Int64x2 to Uint64x2
func (from Int64x2) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Int64x4 to Float32x8
func (from Int64x4) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Int64x4 to Float64x4
func (from Int64x4) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Int64x4 to Int8x32
func (from Int64x4) AsInt8x32() (to Int8x32)

// Int16x16 converts from Int64x4 to Int16x16
func (from Int64x4) AsInt16x16() (to Int16x16)

// Int32x8 converts from Int64x4 to Int32x8
func (from Int64x4) AsInt32x8() (to Int32x8)

// Uint8x32 converts from Int64x4 to Uint8x32
func (from Int64x4) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Int64x4 to Uint16x16
func (from Int64x4) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Int64x4 to Uint32x8
func (from Int64x4) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Int64x4 to Uint64x4
func (from Int64x4) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Int64x8 to Float32x16
func (from Int64x8) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Int64x8 to Float64x8
func (from Int64x8) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Int64x8 to Int8x64
func (from Int64x8) AsInt8x64() (to Int8x64)

// Int16x32 converts from Int64x8 to Int16x32
func (from Int64x8) AsInt16x32() (to Int16x32)

// Int32x16 converts from Int64x8 to Int32x16
func (from Int64x8) AsInt32x16() (to Int32x16)

// Uint8x64 converts from Int64x8 to Uint8x64
func (from Int64x8) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Int64x8 to Uint16x32
func (from Int64x8) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Int64x8 to Uint32x16
func (from Int64x8) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Int64x8 to Uint64x8
func (from Int64x8) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Uint8x16 to Float32x4
func (from Uint8x16) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Uint8x16 to Float64x2
func (from Uint8x16) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Uint8x16 to Int8x16
func (from Uint8x16) AsInt8x16() (to Int8x16)

// Int16x8 converts from Uint8x16 to Int16x8
func (from Uint8x16) AsInt16x8() (to Int16x8)

// Int32x4 converts from Uint8x16 to Int32x4
func (from Uint8x16) AsInt32x4() (to Int32x4)

// Int64x2 converts from Uint8x16 to Int64x2
func (from Uint8x16) AsInt64x2() (to Int64x2)

// Uint16x8 converts from Uint8x16 to Uint16x8
func (from Uint8x16) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Uint8x16 to Uint32x4
func (from Uint8x16) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Uint8x16 to Uint64x2
func (from Uint8x16) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Uint8x32 to Float32x8
func (from Uint8x32) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Uint8x32 to Float64x4
func (from Uint8x32) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Uint8x32 to Int8x32
func (from Uint8x32) AsInt8x32() (to Int8x32)

// Int16x16 converts from Uint8x32 to Int16x16
func (from Uint8x32) AsInt16x16() (to Int16x16)

// Int32x8 converts from Uint8x32 to Int32x8
func (from Uint8x32) AsInt32x8() (to Int32x8)

// Int64x4 converts from Uint8x32 to Int64x4
func (from Uint8x32) AsInt64x4() (to Int64x4)

// Uint16x16 converts from Uint8x32 to Uint16x16
func (from Uint8x32) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Uint8x32 to Uint32x8
func (from Uint8x32) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Uint8x32 to Uint64x4
func (from Uint8x32) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Uint8x64 to Float32x16
func (from Uint8x64) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Uint8x64 to Float64x8
func (from Uint8x64) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Uint8x64 to Int8x64
func (from Uint8x64) AsInt8x64() (to Int8x64)

// Int16x32 converts from Uint8x64 to Int16x32
func (from Uint8x64) AsInt16x32() (to Int16x32)

// Int32x16 converts from Uint8x64 to Int32x16
func (from Uint8x64) AsInt32x16() (to Int32x16)

// Int64x8 converts from Uint8x64 to Int64x8
func (from Uint8x64) AsInt64x8() (to Int64x8)

// Uint16x32 converts from Uint8x64 to Uint16x32
func (from Uint8x64) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Uint8x64 to Uint32x16
func (from Uint8x64) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Uint8x64 to Uint64x8
func (from Uint8x64) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Uint16x8 to Float32x4
func (from Uint16x8) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Uint16x8 to Float64x2
func (from Uint16x8) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Uint16x8 to Int8x16
func (from Uint16x8) AsInt8x16() (to Int8x16)

// Int16x8 converts from Uint16x8 to Int16x8
func (from Uint16x8) AsInt16x8() (to Int16x8)

// Int32x4 converts from Uint16x8 to Int32x4
func (from Uint16x8) AsInt32x4() (to Int32x4)

// Int64x2 converts from Uint16x8 to Int64x2
func (from Uint16x8) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Uint16x8 to Uint8x16
func (from Uint16x8) AsUint8x16() (to Uint8x16)

// Uint32x4 converts from Uint16x8 to Uint32x4
func (from Uint16x8) AsUint32x4() (to Uint32x4)

// Uint64x2 converts from Uint16x8 to Uint64x2
func (from Uint16x8) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Uint16x16 to Float32x8
func (from Uint16x16) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Uint16x16 to Float64x4
func (from Uint16x16) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Uint16x16 to Int8x32
func (from Uint16x16) AsInt8x32() (to Int8x32)

// Int16x16 converts from Uint16x16 to Int16x16
func (from Uint16x16) AsInt16x16() (to Int16x16)

// Int32x8 converts from Uint16x16 to Int32x8
func (from Uint16x16) AsInt32x8() (to Int32x8)

// Int64x4 converts from Uint16x16 to Int64x4
func (from Uint16x16) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Uint16x16 to Uint8x32
func (from Uint16x16) AsUint8x32() (to Uint8x32)

// Uint32x8 converts from Uint16x16 to Uint32x8
func (from Uint16x16) AsUint32x8() (to Uint32x8)

// Uint64x4 converts from Uint16x16 to Uint64x4
func (from Uint16x16) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Uint16x32 to Float32x16
func (from Uint16x32) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Uint16x32 to Float64x8
func (from Uint16x32) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Uint16x32 to Int8x64
func (from Uint16x32) AsInt8x64() (to Int8x64)

// Int16x32 converts from Uint16x32 to Int16x32
func (from Uint16x32) AsInt16x32() (to Int16x32)

// Int32x16 converts from Uint16x32 to Int32x16
func (from Uint16x32) AsInt32x16() (to Int32x16)

// Int64x8 converts from Uint16x32 to Int64x8
func (from Uint16x32) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Uint16x32 to Uint8x64
func (from Uint16x32) AsUint8x64() (to Uint8x64)

// Uint32x16 converts from Uint16x32 to Uint32x16
func (from Uint16x32) AsUint32x16() (to Uint32x16)

// Uint64x8 converts from Uint16x32 to Uint64x8
func (from Uint16x32) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Uint32x4 to Float32x4
func (from Uint32x4) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Uint32x4 to Float64x2
func (from Uint32x4) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Uint32x4 to Int8x16
func (from Uint32x4) AsInt8x16() (to Int8x16)

// Int16x8 converts from Uint32x4 to Int16x8
func (from Uint32x4) AsInt16x8() (to Int16x8)

// Int32x4 converts from Uint32x4 to Int32x4
func (from Uint32x4) AsInt32x4() (to Int32x4)

// Int64x2 converts from Uint32x4 to Int64x2
func (from Uint32x4) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Uint32x4 to Uint8x16
func (from Uint32x4) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Uint32x4 to Uint16x8
func (from Uint32x4) AsUint16x8() (to Uint16x8)

// Uint64x2 converts from Uint32x4 to Uint64x2
func (from Uint32x4) AsUint64x2() (to Uint64x2)

// Float32x8 converts from Uint32x8 to Float32x8
func (from Uint32x8) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Uint32x8 to Float64x4
func (from Uint32x8) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Uint32x8 to Int8x32
func (from Uint32x8) AsInt8x32() (to Int8x32)

// Int16x16 converts from Uint32x8 to Int16x16
func (from Uint32x8) AsInt16x16() (to Int16x16)

// Int32x8 converts from Uint32x8 to Int32x8
func (from Uint32x8) AsInt32x8() (to Int32x8)

// Int64x4 converts from Uint32x8 to Int64x4
func (from Uint32x8) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Uint32x8 to Uint8x32
func (from Uint32x8) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Uint32x8 to Uint16x16
func (from Uint32x8) AsUint16x16() (to Uint16x16)

// Uint64x4 converts from Uint32x8 to Uint64x4
func (from Uint32x8) AsUint64x4() (to Uint64x4)

// Float32x16 converts from Uint32x16 to Float32x16
func (from Uint32x16) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Uint32x16 to Float64x8
func (from Uint32x16) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Uint32x16 to Int8x64
func (from Uint32x16) AsInt8x64() (to Int8x64)

// Int16x32 converts from Uint32x16 to Int16x32
func (from Uint32x16) AsInt16x32() (to Int16x32)

// Int32x16 converts from Uint32x16 to Int32x16
func (from Uint32x16) AsInt32x16() (to Int32x16)

// Int64x8 converts from Uint32x16 to Int64x8
func (from Uint32x16) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Uint32x16 to Uint8x64
func (from Uint32x16) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Uint32x16 to Uint16x32
func (from Uint32x16) AsUint16x32() (to Uint16x32)

// Uint64x8 converts from Uint32x16 to Uint64x8
func (from Uint32x16) AsUint64x8() (to Uint64x8)

// Float32x4 converts from Uint64x2 to Float32x4
func (from Uint64x2) AsFloat32x4() (to Float32x4)

// Float64x2 converts from Uint64x2 to Float64x2
func (from Uint64x2) AsFloat64x2() (to Float64x2)

// Int8x16 converts from Uint64x2 to Int8x16
func (from Uint64x2) AsInt8x16() (to Int8x16)

// Int16x8 converts from Uint64x2 to Int16x8
func (from Uint64x2) AsInt16x8() (to Int16x8)

// Int32x4 converts from Uint64x2 to Int32x4
func (from Uint64x2) AsInt32x4() (to Int32x4)

// Int64x2 converts from Uint64x2 to Int64x2
func (from Uint64x2) AsInt64x2() (to Int64x2)

// Uint8x16 converts from Uint64x2 to Uint8x16
func (from Uint64x2) AsUint8x16() (to Uint8x16)

// Uint16x8 converts from Uint64x2 to Uint16x8
func (from Uint64x2) AsUint16x8() (to Uint16x8)

// Uint32x4 converts from Uint64x2 to Uint32x4
func (from Uint64x2) AsUint32x4() (to Uint32x4)

// Float32x8 converts from Uint64x4 to Float32x8
func (from Uint64x4) AsFloat32x8() (to Float32x8)

// Float64x4 converts from Uint64x4 to Float64x4
func (from Uint64x4) AsFloat64x4() (to Float64x4)

// Int8x32 converts from Uint64x4 to Int8x32
func (from Uint64x4) AsInt8x32() (to Int8x32)

// Int16x16 converts from Uint64x4 to Int16x16
func (from Uint64x4) AsInt16x16() (to Int16x16)

// Int32x8 converts from Uint64x4 to Int32x8
func (from Uint64x4) AsInt32x8() (to Int32x8)

// Int64x4 converts from Uint64x4 to Int64x4
func (from Uint64x4) AsInt64x4() (to Int64x4)

// Uint8x32 converts from Uint64x4 to Uint8x32
func (from Uint64x4) AsUint8x32() (to Uint8x32)

// Uint16x16 converts from Uint64x4 to Uint16x16
func (from Uint64x4) AsUint16x16() (to Uint16x16)

// Uint32x8 converts from Uint64x4 to Uint32x8
func (from Uint64x4) AsUint32x8() (to Uint32x8)

// Float32x16 converts from Uint64x8 to Float32x16
func (from Uint64x8) AsFloat32x16() (to Float32x16)

// Float64x8 converts from Uint64x8 to Float64x8
func (from Uint64x8) AsFloat64x8() (to Float64x8)

// Int8x64 converts from Uint64x8 to Int8x64
func (from Uint64x8) AsInt8x64() (to Int8x64)

// Int16x32 converts from Uint64x8 to Int16x32
func (from Uint64x8) AsInt16x32() (to Int16x32)

// Int32x16 converts from Uint64x8 to Int32x16
func (from Uint64x8) AsInt32x16() (to Int32x16)

// Int64x8 converts from Uint64x8 to Int64x8
func (from Uint64x8) AsInt64x8() (to Int64x8)

// Uint8x64 converts from Uint64x8 to Uint8x64
func (from Uint64x8) AsUint8x64() (to Uint8x64)

// Uint16x32 converts from Uint64x8 to Uint16x32
func (from Uint64x8) AsUint16x32() (to Uint16x32)

// Uint32x16 converts from Uint64x8 to Uint32x16
func (from Uint64x8) AsUint32x16() (to Uint32x16)

// converts from Mask8x16 to Int8x16
func (from Mask8x16) AsInt8x16() (to Int8x16)

// converts from Int8x16 to Mask8x16
func (from Int8x16) AsMask8x16() (to Mask8x16)

func (x Mask8x16) And(y Mask8x16) Mask8x16

func (x Mask8x16) Or(y Mask8x16) Mask8x16

// converts from Mask8x32 to Int8x32
func (from Mask8x32) AsInt8x32() (to Int8x32)

// converts from Int8x32 to Mask8x32
func (from Int8x32) AsMask8x32() (to Mask8x32)

func (x Mask8x32) And(y Mask8x32) Mask8x32

func (x Mask8x32) Or(y Mask8x32) Mask8x32

// converts from Mask8x64 to Int8x64
func (from Mask8x64) AsInt8x64() (to Int8x64)

// converts from Int8x64 to Mask8x64
func (from Int8x64) AsMask8x64() (to Mask8x64)

func (x Mask8x64) And(y Mask8x64) Mask8x64

func (x Mask8x64) Or(y Mask8x64) Mask8x64

// converts from Mask16x8 to Int16x8
func (from Mask16x8) AsInt16x8() (to Int16x8)

// converts from Int16x8 to Mask16x8
func (from Int16x8) AsMask16x8() (to Mask16x8)

func (x Mask16x8) And(y Mask16x8) Mask16x8

func (x Mask16x8) Or(y Mask16x8) Mask16x8

// converts from Mask16x16 to Int16x16
func (from Mask16x16) AsInt16x16() (to Int16x16)

// converts from Int16x16 to Mask16x16
func (from Int16x16) AsMask16x16() (to Mask16x16)

func (x Mask16x16) And(y Mask16x16) Mask16x16

func (x Mask16x16) Or(y Mask16x16) Mask16x16

// converts from Mask16x32 to Int16x32
func (from Mask16x32) AsInt16x32() (to Int16x32)

// converts from Int16x32 to Mask16x32
func (from Int16x32) AsMask16x32() (to Mask16x32)

func (x Mask16x32) And(y Mask16x32) Mask16x32

func (x Mask16x32) Or(y Mask16x32) Mask16x32

// converts from Mask32x4 to Int32x4
func (from Mask32x4) AsInt32x4() (to Int32x4)

// converts from Int32x4 to Mask32x4
func (from Int32x4) AsMask32x4() (to Mask32x4)

func (x Mask32x4) And(y Mask32x4) Mask32x4

func (x Mask32x4) Or(y Mask32x4) Mask32x4

// converts from Mask32x8 to Int32x8
func (from Mask32x8) AsInt32x8() (to Int32x8)

// converts from Int32x8 to Mask32x8
func (from Int32x8) AsMask32x8() (to Mask32x8)

func (x Mask32x8) And(y Mask32x8) Mask32x8

func (x Mask32x8) Or(y Mask32x8) Mask32x8

// converts from Mask32x16 to Int32x16
func (from Mask32x16) AsInt32x16() (to Int32x16)

// converts from Int32x16 to Mask32x16
func (from Int32x16) AsMask32x16() (to Mask32x16)

func (x Mask32x16) And(y Mask32x16) Mask32x16

func (x Mask32x16) Or(y Mask32x16) Mask32x16

// converts from Mask64x2 to Int64x2
func (from Mask64x2) AsInt64x2() (to Int64x2)

// converts from Int64x2 to Mask64x2
func (from Int64x2) AsMask64x2() (to Mask64x2)

func (x Mask64x2) And(y Mask64x2) Mask64x2

func (x Mask64x2) Or(y Mask64x2) Mask64x2

// converts from Mask64x4 to Int64x4
func (from Mask64x4) AsInt64x4() (to Int64x4)

// converts from Int64x4 to Mask64x4
func (from Int64x4) AsMask64x4() (to Mask64x4)

func (x Mask64x4) And(y Mask64x4) Mask64x4

func (x Mask64x4) Or(y Mask64x4) Mask64x4

// converts from Mask64x8 to Int64x8
func (from Mask64x8) AsInt64x8() (to Int64x8)

// converts from Int64x8 to Mask64x8
func (from Int64x8) AsMask64x8() (to Mask64x8)

func (x Mask64x8) And(y Mask64x8) Mask64x8

func (x Mask64x8) Or(y Mask64x8) Mask64x8
